{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b55d62d0",
   "metadata": {},
   "source": [
    "Задача: Выполнить классификацию изображений на наборе notMNIST_small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4df19837-5e1a-437e-818e-3a7c7fb346bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras import layers\n",
    "from keras.metrics import AUC\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import tarfile\n",
    "import os, shutil\n",
    "import cv2\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3f7c39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Activation, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.initializers import GlorotUniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "750e60b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Устанавливаем seed для всех библиотек\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f7fe8c9-15e4-4881-aba5-82caac28060e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MDEtMDEtMDAudHRm.png',\n",
       " 'MDRiXzA4LnR0Zg==.png',\n",
       " 'MjAwcHJvb2Ztb29uc2hpbmUgcmVtaXgudHRm.png',\n",
       " 'MlJlYmVsc0RldXgtQmxhY2sub3Rm.png',\n",
       " 'MlRvb24gU2hhZG93LnR0Zg==.png']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dir = './notMNIST_small'\n",
    "os.listdir(f'{base_dir}/A')[:5]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a97fcc8-ac53-464c-9eab-770f477cc447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = cv2.imread(\"./notMNIST_small/A/Q2FwdGFpbiBTaGluZXIudHRm.png\")    # смотрим вид изображения\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bd2bbe8-73f1-4d83-a25b-c7eb7b13e8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total A images: 1873\n",
      "total B images: 1873\n",
      "total C images: 1873\n",
      "total D images: 1873\n",
      "total E images: 1873\n",
      "total F images: 1873\n",
      "total G images: 1872\n",
      "total H images: 1872\n",
      "total I images: 1872\n",
      "total J images: 1872\n"
     ]
    }
   ],
   "source": [
    "folders = 'ABCDEFGHIJ'    # имеющиеся буквы\n",
    "for folder in folders:\n",
    "  print(f\"total {folder} images: {len(os.listdir(f'{base_dir}/{folder}'))}\")    # смотрим количество данных каждого класса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2aebb6be-cebb-4be1-80a9-69a9af7fc1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./notMNIST_small/A/RGVtb2NyYXRpY2FCb2xkT2xkc3R5bGUgQm9sZC50dGY=.png\n",
      "./notMNIST_small/F/Q3Jvc3NvdmVyIEJvbGRPYmxpcXVlLnR0Zg==.png\n"
     ]
    }
   ],
   "source": [
    "imgs = []\n",
    "labels = []\n",
    "for folder in folders:    # каждая папка с буквами\n",
    "  for img in os.listdir(base_dir + f\"/{folder}\"):   # каждая буква\n",
    "    if img.endswith('.png'):    # только png\n",
    "      try:    # если удалось прочитать \n",
    "        #imgs.append(cv2.imread(base_dir + f\"/{folder}/{img}\")[:, :, 0])   # добавляем изображение\n",
    "        if not np.all(cv2.imread(base_dir + f\"/{folder}/{img}\")[:, :, 0] ==cv2.imread(base_dir + f\"/{folder}/{img}\")[:, :, 0][0]):\n",
    "            imgs.append(cv2.imread(base_dir + f\"/{folder}/{img}\")[:, :, 0])\n",
    "            labels.append(folder)   # добавляем метку класса\n",
    "      except:   # если возникла ошибка при чтении\n",
    "        print(base_dir + f\"/{folder}/{img}\")     # выводим название изображение, которое не удалось прочитать\n",
    "        continue\n",
    "imgs = np.array(imgs).astype('float32')/255.    # масштабируем признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca43b5aa-85b0-4392-854f-cb2e4aab9867",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_categorical(labels):\n",
    "  \"\"\"\n",
    "  This function convert the latter into a categorical shape(view)\n",
    "  labels: this param consists of the letters which will convert\n",
    "  Example: labels -> ['A', 'B'] -> [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]] \n",
    "  \"\"\"\n",
    "  categories = 'ABCDEFGHIJ'\n",
    "  new_labels = np.zeros(shape=(len(labels), len(categories)))\n",
    "  for i, label in enumerate(labels):\n",
    "    new_labels[i][categories.find(label)] = 1 \n",
    "  return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7409b99-19e1-4e48-b50d-4e91f0ac272c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(labels[0])    # выводим пример изображения с меткой\n",
    "labels = to_categorical(labels)\n",
    "plt.imshow(imgs[0])\n",
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a8689d7-3ea0-45cd-9479-5e5112467eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(labels.shape[0])    # перемешиваем данные\n",
    "np.random.shuffle(indices)\n",
    "imgs = imgs[indices]\n",
    "labels = labels[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dacda774-a214-4db8-9d68-189e0a696675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(imgs[0])\n",
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4084dd6-83bd-46f3-94b5-87e9442b0ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape:  (18442, 28, 28)\n",
      "Labels shape:  (18442, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Images shape: \", imgs.shape)   # выводим размеры датасета\n",
    "print(\"Labels shape: \", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b439b01-e1b4-4ec3-a1fa-80d546ce577d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images shape:  (17942, 28, 28)\n",
      "Test images shape:  (500, 28, 28)\n",
      "Train labels shape:  (17942, 10)\n",
      "Test labels shape:  (500, 10)\n"
     ]
    }
   ],
   "source": [
    "# разбиваем на тестовую и тренировочную выборку\n",
    "test_imgs = imgs[:500]\n",
    "test_labels = labels[:500]\n",
    "train_imgs = imgs[500:]\n",
    "train_labels = labels[500:]\n",
    "print(\"Train images shape: \", train_imgs.shape)\n",
    "print(\"Test images shape: \", test_imgs.shape)\n",
    "print(\"Train labels shape: \", train_labels.shape)\n",
    "print(\"Test labels shape: \", test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95ad4469-0bdf-4c41-8072-05148ed70b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавляем измерение для канала (grayscale изображения)\n",
    "train_images = np.expand_dims(train_imgs, axis=-1)  # Форма: (17942, 28, 28, 1)\n",
    "test_images = np.expand_dims(test_imgs, axis=-1)    # Форма: (500, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f1bba7",
   "metadata": {},
   "source": [
    "Обучим и протестируем несколько вариантов сетей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e6368d",
   "metadata": {},
   "source": [
    "1. Без Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a154bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = GlorotUniform(seed=seed)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1), kernel_initializer=initializer),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer=initializer),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer=initializer),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.5, seed=seed),  # Dropout для регуляризации\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')  # Выходной слой для классификации (10 классов)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28628a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e77b6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.5083 - loss: 1.3797 - val_accuracy: 0.7320 - val_loss: 0.6514\n",
      "Epoch 2/20\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7410 - loss: 0.7196 - val_accuracy: 0.7520 - val_loss: 0.5648\n",
      "Epoch 3/20\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7663 - loss: 0.6278 - val_accuracy: 0.7740 - val_loss: 0.5283\n",
      "Epoch 4/20\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7795 - loss: 0.5820 - val_accuracy: 0.7980 - val_loss: 0.4927\n",
      "Epoch 5/20\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7851 - loss: 0.5462 - val_accuracy: 0.7980 - val_loss: 0.4857\n",
      "Epoch 6/20\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8009 - loss: 0.5212 - val_accuracy: 0.7900 - val_loss: 0.4824\n",
      "Epoch 7/20\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8061 - loss: 0.4917 - val_accuracy: 0.8060 - val_loss: 0.4523\n",
      "Epoch 8/20\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8101 - loss: 0.4695 - val_accuracy: 0.8040 - val_loss: 0.4419\n",
      "Epoch 9/20\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8188 - loss: 0.4600 - val_accuracy: 0.8140 - val_loss: 0.4558\n",
      "Epoch 10/20\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8169 - loss: 0.4453 - val_accuracy: 0.8000 - val_loss: 0.4631\n",
      "Epoch 11/20\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8225 - loss: 0.4380 - val_accuracy: 0.7940 - val_loss: 0.4363\n",
      "Epoch 12/20\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8333 - loss: 0.4173 - val_accuracy: 0.8140 - val_loss: 0.4423\n",
      "Epoch 13/20\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8375 - loss: 0.4048 - val_accuracy: 0.8100 - val_loss: 0.4416\n",
      "Epoch 14/20\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8388 - loss: 0.3943 - val_accuracy: 0.8040 - val_loss: 0.4441\n",
      "Epoch 15/20\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8435 - loss: 0.3771 - val_accuracy: 0.8060 - val_loss: 0.4280\n",
      "Epoch 16/20\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8390 - loss: 0.3731 - val_accuracy: 0.8220 - val_loss: 0.4310\n",
      "Epoch 17/20\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8505 - loss: 0.3616 - val_accuracy: 0.8140 - val_loss: 0.4511\n",
      "Epoch 18/20\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8496 - loss: 0.3626 - val_accuracy: 0.8040 - val_loss: 0.4383\n",
      "Epoch 19/20\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8530 - loss: 0.3448 - val_accuracy: 0.8120 - val_loss: 0.4059\n",
      "Epoch 20/20\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8561 - loss: 0.3330 - val_accuracy: 0.8200 - val_loss: 0.4093\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit(\n",
    "    train_images, train_labels,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(test_images, test_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9fcdb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8302 - loss: 0.3917\n",
      "Test accuracy: 0.8199999928474426\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260452cd",
   "metadata": {},
   "source": [
    "2. С использованием Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d62eb518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.6013 - loss: 1.1679 - val_accuracy: 0.7440 - val_loss: 0.6464\n",
      "Epoch 2/20\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - accuracy: 0.7732 - loss: 0.6294 - val_accuracy: 0.7880 - val_loss: 0.5161\n",
      "Epoch 3/20\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.7954 - loss: 0.5424 - val_accuracy: 0.7880 - val_loss: 0.4881\n",
      "Epoch 4/20\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - accuracy: 0.8141 - loss: 0.4940 - val_accuracy: 0.8060 - val_loss: 0.4964\n",
      "Epoch 5/20\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.8268 - loss: 0.4475 - val_accuracy: 0.7980 - val_loss: 0.4977\n",
      "Epoch 6/20\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.8380 - loss: 0.4165 - val_accuracy: 0.8120 - val_loss: 0.4880\n",
      "Epoch 7/20\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - accuracy: 0.8437 - loss: 0.3896 - val_accuracy: 0.8140 - val_loss: 0.4759\n",
      "Epoch 8/20\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.8569 - loss: 0.3544 - val_accuracy: 0.8220 - val_loss: 0.4618\n",
      "Epoch 9/20\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - accuracy: 0.8669 - loss: 0.3287 - val_accuracy: 0.8160 - val_loss: 0.4875\n",
      "Epoch 10/20\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.8693 - loss: 0.3144 - val_accuracy: 0.8300 - val_loss: 0.4689\n",
      "Epoch 11/20\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - accuracy: 0.8808 - loss: 0.2850 - val_accuracy: 0.8060 - val_loss: 0.5778\n",
      "Epoch 12/20\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - accuracy: 0.8841 - loss: 0.2803 - val_accuracy: 0.8260 - val_loss: 0.5338\n",
      "Epoch 13/20\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - accuracy: 0.8956 - loss: 0.2522 - val_accuracy: 0.8040 - val_loss: 0.5833\n",
      "Epoch 14/20\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - accuracy: 0.8958 - loss: 0.2351 - val_accuracy: 0.8080 - val_loss: 0.5619\n",
      "Epoch 15/20\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - accuracy: 0.8973 - loss: 0.2372 - val_accuracy: 0.8060 - val_loss: 0.6265\n",
      "Epoch 16/20\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - accuracy: 0.9047 - loss: 0.2194 - val_accuracy: 0.8060 - val_loss: 0.6449\n",
      "Epoch 17/20\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - accuracy: 0.9095 - loss: 0.2104 - val_accuracy: 0.8140 - val_loss: 0.7003\n",
      "Epoch 18/20\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.9113 - loss: 0.2054 - val_accuracy: 0.8160 - val_loss: 0.6203\n",
      "Epoch 19/20\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.9163 - loss: 0.1924 - val_accuracy: 0.8020 - val_loss: 0.5991\n",
      "Epoch 20/20\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.9184 - loss: 0.1865 - val_accuracy: 0.8260 - val_loss: 0.6341\n"
     ]
    }
   ],
   "source": [
    "initializer = GlorotUniform(seed=seed)\n",
    "# Создание модели\n",
    "model = Sequential([\n",
    "    # Первый сверточный блок\n",
    "    Conv2D(32, (3, 3), kernel_initializer=initializer),  # Сверточный слой\n",
    "    BatchNormalization(),  # Batch Normalization\n",
    "    Activation('relu'),  # Активационная функция\n",
    "    MaxPooling2D((2, 2)),  # Слой подвыборки\n",
    "\n",
    "    # Второй сверточный блок\n",
    "    Conv2D(64, (3, 3), kernel_initializer=initializer),  # Сверточный слой\n",
    "    BatchNormalization(),  # Batch Normalization\n",
    "    Activation('relu'),  # Активационная функция\n",
    "    MaxPooling2D((2, 2)),  # Слой подвыборки\n",
    "\n",
    "    # Третий сверточный блок\n",
    "    Conv2D(128, (3, 3), kernel_initializer=initializer),  # Сверточный слой\n",
    "    BatchNormalization(),  # Batch Normalization\n",
    "    Activation('relu'),  # Активационная функция\n",
    "    MaxPooling2D((2, 2)),  # Слой подвыборки\n",
    "\n",
    "    # Полносвязная часть\n",
    "    Flatten(),  # Преобразование в одномерный вектор\n",
    "    Dense(128),  # Полносвязный слой\n",
    "    BatchNormalization(),  # Batch Normalization\n",
    "    Activation('relu'),  # Активационная функция\n",
    "    Dropout(0.5, seed=seed),  # Dropout для регуляризации\n",
    "\n",
    "    # Выходной слой\n",
    "    Dense(10),  # Полносвязный слой для классификации (10 классов)\n",
    "    Activation('softmax')  # Активационная функция для многоклассовой классификации\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit(\n",
    "    train_images, train_labels,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(test_images, test_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a03168ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8420 - loss: 0.5382\n",
      "Test accuracy: 0.8259999752044678\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4504a4a",
   "metadata": {},
   "source": [
    "3. С использованием Batch Normalization и callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ebbf1274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m558/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5988 - loss: 1.2021\n",
      "Epoch 1: val_accuracy improved from -inf to 0.72800, saving model to best_model.keras\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 18ms/step - accuracy: 0.5995 - loss: 1.1999 - val_accuracy: 0.7280 - val_loss: 0.6875 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m559/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7713 - loss: 0.6314\n",
      "Epoch 2: val_accuracy improved from 0.72800 to 0.76400, saving model to best_model.keras\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - accuracy: 0.7713 - loss: 0.6313 - val_accuracy: 0.7640 - val_loss: 0.5286 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m560/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7946 - loss: 0.5452\n",
      "Epoch 3: val_accuracy improved from 0.76400 to 0.79400, saving model to best_model.keras\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - accuracy: 0.7946 - loss: 0.5452 - val_accuracy: 0.7940 - val_loss: 0.4702 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m558/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8108 - loss: 0.4927\n",
      "Epoch 4: val_accuracy improved from 0.79400 to 0.80600, saving model to best_model.keras\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - accuracy: 0.8108 - loss: 0.4926 - val_accuracy: 0.8060 - val_loss: 0.4989 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8269 - loss: 0.4511\n",
      "Epoch 5: val_accuracy improved from 0.80600 to 0.80800, saving model to best_model.keras\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.8269 - loss: 0.4511 - val_accuracy: 0.8080 - val_loss: 0.4860 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m559/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8348 - loss: 0.4158\n",
      "Epoch 6: val_accuracy improved from 0.80800 to 0.81200, saving model to best_model.keras\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.8348 - loss: 0.4157 - val_accuracy: 0.8120 - val_loss: 0.5005 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m559/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8471 - loss: 0.3879\n",
      "Epoch 7: val_accuracy improved from 0.81200 to 0.82600, saving model to best_model.keras\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - accuracy: 0.8472 - loss: 0.3878 - val_accuracy: 0.8260 - val_loss: 0.4357 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m558/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8512 - loss: 0.3603\n",
      "Epoch 8: val_accuracy did not improve from 0.82600\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - accuracy: 0.8512 - loss: 0.3603 - val_accuracy: 0.8160 - val_loss: 0.4775 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m559/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8613 - loss: 0.3303\n",
      "Epoch 9: val_accuracy did not improve from 0.82600\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.8614 - loss: 0.3302 - val_accuracy: 0.8180 - val_loss: 0.4943 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m560/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8671 - loss: 0.3164\n",
      "Epoch 10: val_accuracy did not improve from 0.82600\n",
      "\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - accuracy: 0.8671 - loss: 0.3163 - val_accuracy: 0.8060 - val_loss: 0.5158 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m558/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8878 - loss: 0.2711\n",
      "Epoch 11: val_accuracy improved from 0.82600 to 0.83600, saving model to best_model.keras\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - accuracy: 0.8878 - loss: 0.2709 - val_accuracy: 0.8360 - val_loss: 0.4588 - learning_rate: 2.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m559/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9031 - loss: 0.2271\n",
      "Epoch 12: val_accuracy improved from 0.83600 to 0.83800, saving model to best_model.keras\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - accuracy: 0.9031 - loss: 0.2271 - val_accuracy: 0.8380 - val_loss: 0.4796 - learning_rate: 2.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m559/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9056 - loss: 0.2115\n",
      "Epoch 13: val_accuracy did not improve from 0.83800\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - accuracy: 0.9056 - loss: 0.2114 - val_accuracy: 0.8260 - val_loss: 0.4952 - learning_rate: 2.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m559/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9158 - loss: 0.1940\n",
      "Epoch 14: val_accuracy did not improve from 0.83800\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.9158 - loss: 0.1940 - val_accuracy: 0.8240 - val_loss: 0.4936 - learning_rate: 2.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m559/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9186 - loss: 0.1862\n",
      "Epoch 15: val_accuracy did not improve from 0.83800\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - accuracy: 0.9187 - loss: 0.1861 - val_accuracy: 0.8220 - val_loss: 0.5007 - learning_rate: 2.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m559/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9216 - loss: 0.1793\n",
      "Epoch 16: val_accuracy did not improve from 0.83800\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - accuracy: 0.9217 - loss: 0.1792 - val_accuracy: 0.8280 - val_loss: 0.4786 - learning_rate: 4.0000e-05\n",
      "Epoch 17/50\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9273 - loss: 0.1663\n",
      "Epoch 17: val_accuracy did not improve from 0.83800\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - accuracy: 0.9273 - loss: 0.1663 - val_accuracy: 0.8340 - val_loss: 0.4811 - learning_rate: 4.0000e-05\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n"
     ]
    }
   ],
   "source": [
    "initializer = GlorotUniform(seed=seed)\n",
    "\n",
    "# Создание модели\n",
    "model = Sequential([\n",
    "    # Первый сверточный блок\n",
    "    Conv2D(32, (3, 3), kernel_initializer=initializer),  # Сверточный слой\n",
    "    BatchNormalization(),  # Batch Normalization\n",
    "    Activation('relu'),  # Активационная функция\n",
    "    MaxPooling2D((2, 2)),  # Слой подвыборки\n",
    "\n",
    "    # Второй сверточный блок\n",
    "    Conv2D(64, (3, 3), kernel_initializer=initializer),  # Сверточный слой\n",
    "    BatchNormalization(),  # Batch Normalization\n",
    "    Activation('relu'),  # Активационная функция\n",
    "    MaxPooling2D((2, 2)),  # Слой подвыборки\n",
    "\n",
    "    # Третий сверточный блок\n",
    "    Conv2D(128, (3, 3), kernel_initializer=initializer),  # Сверточный слой\n",
    "    BatchNormalization(),  # Batch Normalization\n",
    "    Activation('relu'),  # Активационная функция\n",
    "    MaxPooling2D((2, 2)),  # Слой подвыборки\n",
    "\n",
    "    # Полносвязная часть\n",
    "    Flatten(),  # Преобразование в одномерный вектор\n",
    "    Dense(128),  # Полносвязный слой\n",
    "    BatchNormalization(),  # Batch Normalization\n",
    "    Activation('relu'),  # Активационная функция\n",
    "    Dropout(0.5, seed=seed),  # Dropout для регуляризации\n",
    "\n",
    "    # Выходной слой\n",
    "    Dense(10),  # Полносвязный слой для классификации (10 классов)\n",
    "    Activation('softmax')  # Активационная функция для многоклассовой классификации\n",
    "])\n",
    "\n",
    "# Компиляция модели\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Callback'и\n",
    "# 1. ModelCheckpoint: сохраняет лучшую модель\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='best_model.keras',  # Путь для сохранения модели\n",
    "    monitor='val_accuracy',    # Мониторим точность на валидации\n",
    "    save_best_only=True,       # Сохраняем только лучшую модель\n",
    "    mode='max',                # Режим 'max' для точности\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 2. EarlyStopping: останавливает обучение, если нет улучшений\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',    # Мониторим точность на валидации\n",
    "    patience=5,                # Количество эпох без улучшений перед остановкой\n",
    "    restore_best_weights=True, # Восстанавливает веса лучшей модели\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 3. ReduceLROnPlateau: уменьшает learning rate, если нет улучшений\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_accuracy',    # Мониторим точность на валидации\n",
    "    factor=0.2,               # Уменьшаем learning rate в 5 раз\n",
    "    patience=3,               # Количество эпох без улучшений перед уменьшением\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 4. TensorBoard: логирование для визуализации\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Список callback'ов\n",
    "callbacks = [checkpoint, early_stopping, reduce_lr, tensorboard]\n",
    "\n",
    "# Обучение модели\n",
    "history = model.fit(\n",
    "    train_images, train_labels,\n",
    "    batch_size=32,\n",
    "    epochs=50,  # Увеличиваем количество эпох, так как EarlyStopping может остановить обучение раньше\n",
    "    validation_data=(test_images, test_labels),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "391730be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8436 - loss: 0.4306\n",
      "Test accuracy: 0.8379999995231628\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d00c2d9",
   "metadata": {},
   "source": [
    "4. Изменена структура сети (размерность слоев)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97b1a05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Инициализатор с фиксированным seed\n",
    "seed = 42\n",
    "initializer = GlorotUniform(seed=seed)\n",
    "\n",
    "# Создание модели\n",
    "model = Sequential([\n",
    "    # Первый блок сверток\n",
    "    Conv2D(32, (3, 3), padding='same', kernel_initializer=initializer, kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Conv2D(32, (3, 3), padding='same', kernel_initializer=initializer, kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25, seed=seed),\n",
    "\n",
    "    # Второй блок сверток\n",
    "    Conv2D(64, (3, 3), padding='same', kernel_initializer=initializer, kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Conv2D(64, (3, 3), padding='same', kernel_initializer=initializer, kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25, seed=seed),\n",
    "\n",
    "    # Третий блок сверток\n",
    "    Conv2D(128, (3, 3), padding='same', kernel_initializer=initializer, kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Conv2D(128, (3, 3), padding='same', kernel_initializer=initializer, kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25, seed=seed),\n",
    "\n",
    "    # Четвертый блок сверток\n",
    "    Conv2D(256, (3, 3), padding='same', kernel_initializer=initializer, kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Conv2D(256, (3, 3), padding='same', kernel_initializer=initializer, kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    GlobalAveragePooling2D(),  # Глобальный средний пулинг вместо Flatten\n",
    "    Dropout(0.5, seed=seed),\n",
    "\n",
    "    # Полносвязный слой\n",
    "    Dense(256, kernel_initializer=initializer, kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Dropout(0.5, seed=seed),\n",
    "\n",
    "    # Выходной слой\n",
    "    Dense(10, kernel_initializer=initializer),  # 10 классов\n",
    "    Activation('softmax')\n",
    "])\n",
    "\n",
    "# Компиляция модели\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4405891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.6264 - loss: 2.2331\n",
      "Epoch 1: val_accuracy improved from -inf to 0.15000, saving model to best_model.keras\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 136ms/step - accuracy: 0.6270 - loss: 2.2311 - val_accuracy: 0.1500 - val_loss: 5.9405 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.9098 - loss: 1.1137\n",
      "Epoch 2: val_accuracy improved from 0.15000 to 0.91600, saving model to best_model.keras\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 134ms/step - accuracy: 0.9098 - loss: 1.1134 - val_accuracy: 0.9160 - val_loss: 0.9139 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.9237 - loss: 0.8425\n",
      "Epoch 3: val_accuracy did not improve from 0.91600\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 131ms/step - accuracy: 0.9237 - loss: 0.8423 - val_accuracy: 0.9120 - val_loss: 0.7240 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.9252 - loss: 0.6880\n",
      "Epoch 4: val_accuracy improved from 0.91600 to 0.92400, saving model to best_model.keras\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 131ms/step - accuracy: 0.9252 - loss: 0.6878 - val_accuracy: 0.9240 - val_loss: 0.5818 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.9305 - loss: 0.5821\n",
      "Epoch 5: val_accuracy improved from 0.92400 to 0.93400, saving model to best_model.keras\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 132ms/step - accuracy: 0.9305 - loss: 0.5821 - val_accuracy: 0.9340 - val_loss: 0.5629 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.9322 - loss: 0.5333\n",
      "Epoch 6: val_accuracy did not improve from 0.93400\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 132ms/step - accuracy: 0.9322 - loss: 0.5332 - val_accuracy: 0.9340 - val_loss: 0.4934 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.9324 - loss: 0.5109\n",
      "Epoch 7: val_accuracy did not improve from 0.93400\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 136ms/step - accuracy: 0.9324 - loss: 0.5109 - val_accuracy: 0.9200 - val_loss: 0.5294 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.9357 - loss: 0.4804\n",
      "Epoch 8: val_accuracy improved from 0.93400 to 0.94800, saving model to best_model.keras\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 135ms/step - accuracy: 0.9357 - loss: 0.4804 - val_accuracy: 0.9480 - val_loss: 0.4355 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.9347 - loss: 0.4840\n",
      "Epoch 9: val_accuracy did not improve from 0.94800\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 130ms/step - accuracy: 0.9347 - loss: 0.4840 - val_accuracy: 0.9240 - val_loss: 0.5051 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.9339 - loss: 0.4770\n",
      "Epoch 10: val_accuracy did not improve from 0.94800\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 128ms/step - accuracy: 0.9339 - loss: 0.4770 - val_accuracy: 0.9320 - val_loss: 0.4826 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.9384 - loss: 0.4655\n",
      "Epoch 11: val_accuracy did not improve from 0.94800\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 126ms/step - accuracy: 0.9384 - loss: 0.4655 - val_accuracy: 0.9380 - val_loss: 0.4335 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.9497 - loss: 0.4025\n",
      "Epoch 12: val_accuracy improved from 0.94800 to 0.96400, saving model to best_model.keras\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 129ms/step - accuracy: 0.9498 - loss: 0.4024 - val_accuracy: 0.9640 - val_loss: 0.3325 - learning_rate: 2.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.9615 - loss: 0.3344\n",
      "Epoch 13: val_accuracy did not improve from 0.96400\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 127ms/step - accuracy: 0.9615 - loss: 0.3343 - val_accuracy: 0.9560 - val_loss: 0.3234 - learning_rate: 2.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.9630 - loss: 0.3068\n",
      "Epoch 14: val_accuracy did not improve from 0.96400\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 125ms/step - accuracy: 0.9630 - loss: 0.3068 - val_accuracy: 0.9540 - val_loss: 0.3118 - learning_rate: 2.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.9654 - loss: 0.2789\n",
      "Epoch 15: val_accuracy did not improve from 0.96400\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 125ms/step - accuracy: 0.9654 - loss: 0.2789 - val_accuracy: 0.9540 - val_loss: 0.3043 - learning_rate: 2.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.9677 - loss: 0.2592\n",
      "Epoch 16: val_accuracy improved from 0.96400 to 0.96600, saving model to best_model.keras\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 125ms/step - accuracy: 0.9677 - loss: 0.2591 - val_accuracy: 0.9660 - val_loss: 0.2678 - learning_rate: 4.0000e-05\n",
      "Epoch 17/50\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.9770 - loss: 0.2275\n",
      "Epoch 17: val_accuracy did not improve from 0.96600\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 130ms/step - accuracy: 0.9770 - loss: 0.2275 - val_accuracy: 0.9640 - val_loss: 0.2623 - learning_rate: 4.0000e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.9756 - loss: 0.2229\n",
      "Epoch 18: val_accuracy did not improve from 0.96600\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 126ms/step - accuracy: 0.9756 - loss: 0.2229 - val_accuracy: 0.9640 - val_loss: 0.2648 - learning_rate: 4.0000e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.9778 - loss: 0.2126\n",
      "Epoch 19: val_accuracy improved from 0.96600 to 0.97000, saving model to best_model.keras\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 129ms/step - accuracy: 0.9778 - loss: 0.2126 - val_accuracy: 0.9700 - val_loss: 0.2600 - learning_rate: 4.0000e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.9799 - loss: 0.2027\n",
      "Epoch 20: val_accuracy improved from 0.97000 to 0.97200, saving model to best_model.keras\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 127ms/step - accuracy: 0.9800 - loss: 0.2026 - val_accuracy: 0.9720 - val_loss: 0.2465 - learning_rate: 4.0000e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.9803 - loss: 0.1978\n",
      "Epoch 21: val_accuracy did not improve from 0.97200\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 126ms/step - accuracy: 0.9803 - loss: 0.1977 - val_accuracy: 0.9700 - val_loss: 0.2444 - learning_rate: 4.0000e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.9810 - loss: 0.1910\n",
      "Epoch 22: val_accuracy did not improve from 0.97200\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 127ms/step - accuracy: 0.9810 - loss: 0.1909 - val_accuracy: 0.9660 - val_loss: 0.2554 - learning_rate: 4.0000e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.9825 - loss: 0.1821\n",
      "Epoch 23: val_accuracy did not improve from 0.97200\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 126ms/step - accuracy: 0.9825 - loss: 0.1820 - val_accuracy: 0.9620 - val_loss: 0.2532 - learning_rate: 4.0000e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.9841 - loss: 0.1748\n",
      "Epoch 24: val_accuracy did not improve from 0.97200\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 126ms/step - accuracy: 0.9841 - loss: 0.1747 - val_accuracy: 0.9700 - val_loss: 0.2471 - learning_rate: 8.0000e-06\n",
      "Epoch 25/50\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.9845 - loss: 0.1756\n",
      "Epoch 25: val_accuracy did not improve from 0.97200\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 127ms/step - accuracy: 0.9845 - loss: 0.1755 - val_accuracy: 0.9700 - val_loss: 0.2443 - learning_rate: 8.0000e-06\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "# Callback'и\n",
    "# 1. ModelCheckpoint: сохраняет лучшую модель\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='best_model.keras',  # Путь для сохранения модели\n",
    "    monitor='val_accuracy',    # Мониторим точность на валидации\n",
    "    save_best_only=True,       # Сохраняем только лучшую модель\n",
    "    mode='max',                # Режим 'max' для точности\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 2. EarlyStopping: останавливает обучение, если нет улучшений\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',    # Мониторим точность на валидации\n",
    "    patience=5,                # Количество эпох без улучшений перед остановкой\n",
    "    restore_best_weights=True, # Восстанавливает веса лучшей модели\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 3. ReduceLROnPlateau: уменьшает learning rate, если нет улучшений\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_accuracy',    # Мониторим точность на валидации\n",
    "    factor=0.2,               # Уменьшаем learning rate в 5 раз\n",
    "    patience=3,               # Количество эпох без улучшений перед уменьшением\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 4. TensorBoard: логирование для визуализации\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Список callback'ов\n",
    "callbacks = [checkpoint, early_stopping, reduce_lr, tensorboard]\n",
    "\n",
    "# Обучение модели\n",
    "history = model.fit(\n",
    "    train_images, train_labels,\n",
    "    batch_size=64,\n",
    "    epochs=50,\n",
    "    validation_data=(test_images, test_labels),\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e80bf5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9698 - loss: 0.2152\n",
      "Test accuracy: 0.972000002861023\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a53a5fe",
   "metadata": {},
   "source": [
    "В ходе работы обучены несколько разлиных моделей. Сначала обучены несколько моделей, состоящих из 3 сверточных слоев, а после структура усложнена с целью получить наиболее высокие метрики. Использовался GlorotUniform для одинаковой инлизициаации весов различных моделей.\n",
    "1. В первой части работы:\n",
    "    Лучшее полученное значение accuracy: 0.862 (С использованием Batch Normalization и callbacks). Добавление BN в структуру модели (вариант 2) незначительно улудшило метрики в сравнении с первым случаем (на 0,5%).\n",
    "    \n",
    "2. Для более сложной модели, состоящей из 4 сверточных и 1 полносвязного слоев, метрика accuracy составила 0.972."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
