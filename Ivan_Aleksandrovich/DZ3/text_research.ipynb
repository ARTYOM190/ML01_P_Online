{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание:\n",
    "1.\tЗагрузить файл длиной не менее 2000 символов. \n",
    "2.\tСоставить программу, которая считает число уникальных слов в тексте (без критерия схожести)\n",
    "3.\tСоставить программу, которая считает число гласных и согласных букв. \n",
    "4.\tСоставить программу, которая считает число предложений, их длину и число (количество) раз использования каждого слова в тексте (с критерием схожести, критерий схожести слов выбрать самостоятельно, например, spacy (en_core_web_sm) или расстояние Левенштейна). \n",
    "5.\tВывести 10 наиболее часто встречаемых слов. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этапы решения задачи:\n",
    "1. Загрузить текстовый файл с помощью open() и file.read().\n",
    "2. Разделить текст на слова, убрать знаки препинания и привести все символы к нижнему регистру.\n",
    "3. Добавить слова в set, чтобы посчитать количество уникальных слов.\n",
    "4. Создать списки гласных и согласных букв с помощью регулярных выражений.\n",
    "5. Загрузить модуль spacy для работы с предложениями.\n",
    "6. Посчитать длину и количество предложений с помощью spacy.\n",
    "7. Привести слова в тексте к начальной форме с помощью spacy, посчитать входимость каждого слова в текст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем отрывок текста из файла text.txt\n",
    "import os\n",
    "file = open('text.txt', 'r')\n",
    "text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# С помощью регулярных выражений отделям слова и убираем знаки препинания, а также приводим текст к нижнему регистру\n",
    "import re\n",
    "words = re.findall(r\"\\b\\w+(?:'\\w+)?\\b\", text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество уникальных слов: 192\n"
     ]
    }
   ],
   "source": [
    "# Выделям уникальные слова с помощью добавления их в set\n",
    "uniq_words = set(words)\n",
    "print (\"Количество уникальных слов:\", len(uniq_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество гласных: 609\n",
      "Количество согласных: 1033\n"
     ]
    }
   ],
   "source": [
    "# Найдем и выведем количество гласных и согласных букв в тексте с помощью регулярных выражений\n",
    "vowels = re.findall(r'[aeiouAEIOU]', text)\n",
    "consonants = re.findall(r'[bcdfghjklmnpqrstvwxyzBCDFGHJKLMNPQRSTVWXYZ]', text)\n",
    "print (\"Количество гласных:\", len(vowels))\n",
    "print (\"Количество согласных:\", len(consonants))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Номер предложения: 1  Длина предложения:  23\n",
      "Номер предложения: 2  Длина предложения:  48\n",
      "Номер предложения: 3  Длина предложения:  13\n",
      "Номер предложения: 4  Длина предложения:  35\n",
      "Номер предложения: 5  Длина предложения:  8\n",
      "Номер предложения: 6  Длина предложения:  22\n",
      "Номер предложения: 7  Длина предложения:  5\n",
      "Номер предложения: 8  Длина предложения:  10\n",
      "Номер предложения: 9  Длина предложения:  8\n",
      "Номер предложения: 10  Длина предложения:  45\n",
      "Номер предложения: 11  Длина предложения:  54\n",
      "Номер предложения: 12  Длина предложения:  94\n",
      "В тексте 12 предложений\n"
     ]
    }
   ],
   "source": [
    "#Реализуем подсчет количества и длины предложений с помощью spacy\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(text)\n",
    "counter = 1\n",
    "\n",
    "for sentence in doc.sents:\n",
    "   # print (counter)\n",
    "    print(\"Номер предложения:\" , counter, \" Длина предложения: \", len(sentence.text.split(' ')))\n",
    "    counter +=1\n",
    "print (\"В тексте\", counter-1, \"предложений\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для подсчета наиболее встречаемых слов в тексте с учетом схожести также применим spacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 наиболее часто встречаемых слов в тексте: \n",
      "the\n",
      "of\n",
      "was\n",
      "a\n",
      "in\n",
      "to\n",
      "it\n",
      "and\n",
      "that\n",
      "be\n"
     ]
    }
   ],
   "source": [
    "# Извлекаем слова в начальной форме, добавляем их в словарь и считаем количество вхождений\n",
    "doc = nlp(' '.join(words))\n",
    "tokens = {}\n",
    "counter = 0\n",
    "for token in doc:\n",
    "    token = str(token)\n",
    "    if token in tokens.keys():\n",
    "        tokens[token] += 1\n",
    "    else:\n",
    "        tokens[token] = 1\n",
    "# Сортируем словарь по количеству вхождений и выводим 10 наиболее часто встречаемых слов в тексте\n",
    "sorted_tokens = sorted(tokens.items(), key= lambda item: item[1],reverse=1)\n",
    "print (\"10 наиболее часто встречаемых слов в тексте: \")\n",
    "for item in sorted_tokens[0:10]:\n",
    "    print (item[0])\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DZ3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
