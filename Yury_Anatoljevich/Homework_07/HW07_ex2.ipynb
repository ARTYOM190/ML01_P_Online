{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Домашнее задание по занятию №7.\n",
    "Задание №2.\n",
    "***\n",
    "Реализовать с использованием потоков и процессов скачивание файлов из интернета. \n",
    "Список файлов для скачивания подготовить самостоятельно (например изображений, не менее 100 изображений или других объектов). Сравнить производительность с последовательным методом. Сравнить производительность Thread и multiprocessing решений. Попробовать подобрать оптимальное число потоков/процессов. \n",
    "\n",
    "***\n",
    "Анализ задания и алгоритм выполнения.\n",
    "Находим простую страницу в интернете с картинками, имеющими url адреса (вместо выдачи с помощью JavaScript)\n",
    "Скачиваем страницу, анализируем ее на наличие url адресов картинок.\n",
    "Адреса картинок помещаем в список.\n",
    "Затем загружаем картинки по списку:\n",
    "а)  последовательно одну за другой\n",
    "*) с помощью Thread\n",
    "*) с помощью multiprocessing\n",
    "В каждом случае засекаем время скачивания\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import urllib.request\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
    "\n",
    "\n",
    "# Function to extract a list of image urls from a text of an internet page\n",
    "# page - the html page to extract urls of images from\n",
    "# protocol - the protocol of the website like \"http\" or \"https\"\n",
    "#\n",
    "def get_img_url_in_text(page, protocol):\n",
    "    urls = []\n",
    "    all_urls = re.findall(r'((http\\:|https\\:)?\\/\\/[^\"\\' ]*?\\.(png|jpg))', page, flags=re.IGNORECASE | re.MULTILINE | re.UNICODE)\n",
    "    for url in all_urls:\n",
    "        if not url[0].startswith(\"http\"):\n",
    "            urls.append(protocol + url[0])\n",
    "        else:\n",
    "            urls.append(url[0])\n",
    "    return urls\n",
    "\n",
    "# Function to download a page and then evoke the function above to extract image urls:\n",
    "#\n",
    "def get_images_from_url(url):\n",
    "    protocol = url.split('/')[0]\n",
    "    try:\n",
    "        resp = requests.get(url)\n",
    "        return get_img_url_in_text(resp.text, protocol)\n",
    "    except:\n",
    "        print(\"Error while the page loading\\nNo image address can be extracted\")\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добываем список адресов картинок из задаваемого нами url. При этом скачивается страница,  после чего анализируется на наличие ссылок на картинки.\n",
    "Ссылки извлекаются в список."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.theshermantank.com/sherman/45-gallery-2-more-random-high-resolution-sherman-photos-with-comments/\"\n",
    "# url = \"https://www.theshermantank.com/\"\n",
    "image_list = get_images_from_url(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем адреса первых десяти картинок:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URLs of several pictures:\n",
      "https://www.theshermantank.com/wp-content/uploads/sherman-tank-site-top-1.jpg\n",
      "https://www.theshermantank.com/wp-content/uploads/2015/11/cropped-AnnoM4A3E8_Sherman-32x32.png\n",
      "https://www.theshermantank.com/wp-content/uploads/2015/11/cropped-AnnoM4A3E8_Sherman-192x192.png\n",
      "https://www.theshermantank.com/wp-content/uploads/2015/11/cropped-AnnoM4A3E8_Sherman-180x180.png\n",
      "https://www.theshermantank.com/wp-content/uploads/2015/11/cropped-AnnoM4A3E8_Sherman-270x270.png\n",
      "https://www.theshermantank.com/wp-content/uploads/M4Sherman_M1dozerblade_1945.jpg\n",
      "https://www.theshermantank.com/wp-content/uploads/M4Sherman_M1dozerblade_1945.jpg\n",
      "https://www.theshermantank.com/wp-content/uploads/M4Sherman_M1dozerblade_1945.jpg\n",
      "https://www.theshermantank.com/wp-content/uploads/M4Sherman_M1dozerblade_1945-300x228.jpg\n",
      "https://www.theshermantank.com/wp-content/uploads/M4_Sherman_105_1944-1.jpg\n",
      "Total number of images found in the page: 289\n"
     ]
    }
   ],
   "source": [
    "print('URLs of several pictures:')\n",
    "i = 0\n",
    "while i < 10 and i < len(image_list):\n",
    "    print(image_list[i])\n",
    "    i += 1\n",
    "print(f'Total number of images found in the page: {len(image_list)}')\n",
    "\n",
    "# extracting addresses for 100 images\n",
    "if len(image_list) > 16:\n",
    "    image_list = image_list[0:16]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что страница включает 289 картинок."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачивание картинок последовательно одной за другой, без распараллеливания. \n",
    "Засекаем время и выводим на экран."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\CurrentWork\\ML\\Lesson07_Python_decorators_threads\\Homework_07/images/sherman-tank-site-top-1.jpg\n",
      "d:\\CurrentWork\\ML\\Lesson07_Python_decorators_threads\\Homework_07/images/cropped-AnnoM4A3E8_Sherman-32x32.png\n",
      "d:\\CurrentWork\\ML\\Lesson07_Python_decorators_threads\\Homework_07/images/cropped-AnnoM4A3E8_Sherman-192x192.png\n",
      "d:\\CurrentWork\\ML\\Lesson07_Python_decorators_threads\\Homework_07/images/cropped-AnnoM4A3E8_Sherman-180x180.png\n",
      "d:\\CurrentWork\\ML\\Lesson07_Python_decorators_threads\\Homework_07/images/cropped-AnnoM4A3E8_Sherman-270x270.png\n",
      "d:\\CurrentWork\\ML\\Lesson07_Python_decorators_threads\\Homework_07/images/M4Sherman_M1dozerblade_1945.jpg\n",
      "d:\\CurrentWork\\ML\\Lesson07_Python_decorators_threads\\Homework_07/images/M4Sherman_M1dozerblade_1945.jpg\n",
      "d:\\CurrentWork\\ML\\Lesson07_Python_decorators_threads\\Homework_07/images/M4Sherman_M1dozerblade_1945.jpg\n",
      "d:\\CurrentWork\\ML\\Lesson07_Python_decorators_threads\\Homework_07/images/M4Sherman_M1dozerblade_1945-300x228.jpg\n",
      "d:\\CurrentWork\\ML\\Lesson07_Python_decorators_threads\\Homework_07/images/M4_Sherman_105_1944-1.jpg\n",
      "d:\\CurrentWork\\ML\\Lesson07_Python_decorators_threads\\Homework_07/images/M4_Sherman_105_1944-1.jpg\n",
      "d:\\CurrentWork\\ML\\Lesson07_Python_decorators_threads\\Homework_07/images/M4_Sherman_105_1944-1.jpg\n",
      "d:\\CurrentWork\\ML\\Lesson07_Python_decorators_threads\\Homework_07/images/M4_Sherman_105_1944-1-300x200.jpg\n",
      "d:\\CurrentWork\\ML\\Lesson07_Python_decorators_threads\\Homework_07/images/2AD_FDM4_1945.jpg\n",
      "d:\\CurrentWork\\ML\\Lesson07_Python_decorators_threads\\Homework_07/images/2AD_FDM4_1945.jpg\n",
      "d:\\CurrentWork\\ML\\Lesson07_Python_decorators_threads\\Homework_07/images/2AD_FDM4_1945.jpg\n",
      "Time of sequential download of the pictures: 165.61670810000214 s\n"
     ]
    }
   ],
   "source": [
    "dir = os.getcwd() + \"/\" + \"images\" # folder for images to be downloaded\n",
    "time1 = time.perf_counter() # starting the timer\n",
    "\n",
    "for image_address in image_list:\n",
    "    try:\n",
    "        filename = dir + \"/\" + image_address.split('/')[-1] # filename includes the folder and the original picture name\n",
    "        print(filename)\n",
    "        urllib.request.urlretrieve(image_address, filename) # downloading the page        \n",
    "    except:\n",
    "        print(f\"Error downloading file\")\n",
    "\n",
    "time2 = time.perf_counter() # stopping the timer\n",
    "time_sequential = time2-time1\n",
    "print(f'Time of sequential download of the pictures: {time_sequential} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачивание картинок с помощью потоков (Threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\CurrentWork\\ML\\Lesson07_Python_decorators_threads\\Homework_07/images/sherman-tank-site-top-1.jpg\n",
      "d:\\CurrentWork\\ML\\Lesson07_Python_decorators_threads\\Homework_07/images/cropped-AnnoM4A3E8_Sherman-32x32.png\n",
      "d:\\CurrentWork\\ML\\Lesson07_Python_decorators_threads\\Homework_07/images/cropped-AnnoM4A3E8_Sherman-192x192.png\n",
      "d:\\CurrentWork\\ML\\Lesson07_Python_decorators_threads\\Homework_07/images/cropped-AnnoM4A3E8_Sherman-180x180.png\n",
      "d:\\CurrentWork\\ML\\Lesson07_Python_decorators_threads\\Homework_07/images/cropped-AnnoM4A3E8_Sherman-270x270.png\n",
      "d:\\CurrentWork\\ML\\Lesson07_Python_decorators_threads\\Homework_07/images/M4Sherman_M1dozerblade_1945.jpg\n",
      "d:\\CurrentWork\\ML\\Lesson07_Python_decorators_threads\\Homework_07/images/M4Sherman_M1dozerblade_1945.jpg\n",
      "d:\\CurrentWork\\ML\\Lesson07_Python_decorators_threads\\Homework_07/images/M4Sherman_M1dozerblade_1945.jpg\n",
      "d:\\CurrentWork\\ML\\Lesson07_Python_decorators_threads\\Homework_07/images/M4Sherman_M1dozerblade_1945-300x228.jpg\n",
      "d:\\CurrentWork\\ML\\Lesson07_Python_decorators_threads\\Homework_07/images/M4_Sherman_105_1944-1.jpg\n",
      "d:\\CurrentWork\\ML\\Lesson07_Python_decorators_threads\\Homework_07/images/M4_Sherman_105_1944-1.jpg\n",
      "d:\\CurrentWork\\ML\\Lesson07_Python_decorators_threads\\Homework_07/images/M4_Sherman_105_1944-1.jpg\n",
      "d:\\CurrentWork\\ML\\Lesson07_Python_decorators_threads\\Homework_07/images/M4_Sherman_105_1944-1-300x200.jpg\n",
      "d:\\CurrentWork\\ML\\Lesson07_Python_decorators_threads\\Homework_07/images/2AD_FDM4_1945.jpg\n",
      "d:\\CurrentWork\\ML\\Lesson07_Python_decorators_threads\\Homework_07/images/2AD_FDM4_1945.jpg\n",
      "d:\\CurrentWork\\ML\\Lesson07_Python_decorators_threads\\Homework_07/images/2AD_FDM4_1945.jpg\n",
      "Time of multi-threaded download of the pictures: 22.15297759999885 s\n"
     ]
    }
   ],
   "source": [
    "time1 = time.perf_counter()\n",
    "\n",
    "with ThreadPoolExecutor(max_workers = 16) as exec:\n",
    "        futures = []\n",
    "        for image_address in image_list:\n",
    "            try:\n",
    "                filename = dir + \"/\" + image_address.split('/')[-1] # filename includes the folder and the original picture name\n",
    "                # print(filename)                \n",
    "                futures.append(exec.submit(urllib.request.urlretrieve, image_address, filename)) # downloading the page in threads\n",
    "            except:\n",
    "                 print('Image download fail')\n",
    "\n",
    "time2 = time.perf_counter() # stopping the timer\n",
    "time_multithread = time2-time1\n",
    "print(f'Time of multi-threaded download of the pictures: {time_multithread} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачивание картинок с помощью параллельных процессов (multiprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of multi-process download of the pictures: 22.07577499999752 s\n"
     ]
    }
   ],
   "source": [
    "time1 = time.perf_counter()\n",
    "\n",
    "with ProcessPoolExecutor(max_workers = 16) as exec:\n",
    "        futures = []\n",
    "        for image_address in image_list:\n",
    "            try:\n",
    "                filename = dir + \"/\" + image_address.split('/')[-1] # filename includes the folder and the original picture name\n",
    "                # print(filename)                \n",
    "                futures.append(exec.submit(urllib.request.urlretrieve, image_address, filename)) # downloading the page in threads\n",
    "            except:\n",
    "                 print('Image download fail')\n",
    "\n",
    "time2 = time.perf_counter() # stopping the timer\n",
    "time_multiprocess = time2-time1\n",
    "print(f'Time of multi-process download of the pictures: {time_multiprocess} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравниваем время скачивания тремя методами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for sequential download: 165.61670810000214\n",
      "Time for multithread download: 22.15297759999885\n",
      "Time for multiprocess download: 22.07577499999752\n",
      "Benefit from multithread download vs sequential, %: 86.62394763539044\n",
      "Benefit from multiprocess download vs sequential, %: 86.67056285971594\n"
     ]
    }
   ],
   "source": [
    "print(f\"Time for sequential download: {time_sequential}\")\n",
    "print(f\"Time for multithread download: {time_multithread}\")\n",
    "print(f\"Time for multiprocess download: {time_multiprocess}\")\n",
    "print(f\"Benefit from multithread download vs sequential, %: {(time_sequential - time_multithread) / time_sequential *100}\")\n",
    "print(f\"Benefit from multiprocess download vs sequential, %: {(time_sequential - time_multiprocess) / time_sequential *100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводы:\n",
    "В ходе выполнения задания реализовано скачивание набора картинок с интернет-страницы тремя методами: \n",
    "    ●   Последовательный метод\n",
    "    ●   Параллельными потоками\n",
    "    ●   Параллельными процессами\n",
    "В качестве замечания отметим, что очень большое время ушло на поиск подходящей web-страницы со статическими адресами картинок. Большинство страниц с динамически формируемым содержимым не позволяют извлечь адреса картинок для последующего скачивания.\n",
    "В ходе работы было показано, что использование параллельной обработки позволяет ускорить скачивание набора файлов.\n",
    "Ускорение от перехода к параллельному скачиванию в нашем случае позволяет сократить время скачивания примерно на порядок (иногда чуть больше чем в 10 раз, иногда меньше). При этом дополнительная сложность для оценки требуемого времени скачивания вносится нестабильностью скорости интернет-соединения.\n",
    "Для оценки оптимального числа потоков мы использовали 16 файлов вместо 100 в связи с большими затратами времени на такие эксперименты. Если при последовательном скачивании 16 файлов потребовалось ~180 с, то параллельные потоки позволяют уменьшить это время: для 2 потоков временные затраты составляют уже ~80-100 c, и далее монотонно падают до ~16-22 с при увеличении числа потоков до 16. По всей видимости, должен существовать оптимум числа потоков, после которого дальшейшее увеличение их числа уже не будет давать выигрыша и даже приводить к увеличению требуемого времени скачивания (кто застал эпоху масс-даунлоадеров наподобие Download Master, знает об этом на собственном опыте). Иногда (хоть и не всегда) выход на плато по времени скачивания наблюдается уже начиная с 12 потоков.\n",
    "Отметим, что измерения проводились на четыреъядерном процессоре с hyperthreading, то есть имеющем 8 аппаратных потоков выполнения.\n",
    "Что касается влияния числа процессов на скорость скачивания, то из-за упомянутой нестабильности результатов сложно оценить, насколько различный результат дает многопоточная и многопроцессная обработка потоков скачивания. В целом, в условиях нашего эксперимента наблюдалось более-менее эквивалентное поведение: при увеличении числа процессов время скачивания падает, при равном числе потоков и процессов время более-менее одинаковое (с учетом нестабильности интернет-соединения). Иногда наблюдалось, что использование параллельных потоков дает больший выигрыш, чем использование параллельных процессов, иногда наоборот. С одной стороны, из-за накладных расходов времени, требуемого для запуска каждого последующего процесса, использование параллельных потоков может быть выгоднее параллельных процессов. С другой стороны, независимое выполнение процесоов на разных ядрах процессора может дать преимущество именно для обработки с помощью параллельных процессов. \n",
    "в целом можно сделать вывод, что в условиях нашего эксперимента увеличение числа потоков/процессов до 12-16 является целесообразным."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
