{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание:\n",
    "1.\tЗагрузить файл длиной не менее 2000 символов. \n",
    "2.\tСоставить программу, которая считает число уникальных слов в тексте (без критерия схожести)\n",
    "3.\tСоставить программу, которая считает число гласных и согласных букв. \n",
    "4.\tСоставить программу, которая считает число предложений, их длину и число (количество) раз использования каждого слова в тексте (с критерием схожести, критерий схожести слов выбрать самостоятельно, например, spacy (en_core_web_sm) или расстояние Левенштейна). \n",
    "5.\tВывести 10 наиболее часто встречаемых слов. \n",
    "\n",
    "***\n",
    "В данном блокноте выполняем пункт 4 и 5 задания.\n",
    "\n",
    "***\n",
    "Анализ по данным пунктам задания:\n",
    "a) Для подсчета числа предложений можно находить знаки конца предложения (точку, вопросительный и восклицательный знак). Если между предыдущим таким знаком (или началом текста) и текущим знаком находится хотя бы один алфавитно-цифровой знак, то это и будет предложение.\n",
    "Таким образом, можно разбить текст на список предложений. Длина списка будет числом предложений в тексте.\n",
    "b) Для отыскания длины каждого предложения можно предварительно очистить каждое предложение в списке от знаков препинания, заменив их пробелами, и расщепить на список слов с помощью соответствующей процедуры Python. Длина этого списка будет длиной предложения.\n",
    "c) Для нахождения числа раз использования каждого слова в тексте с использованием критерия схожести используем библиотеку spacy. \n",
    "Вначале мы уберем из текста все знаки препинания и разделим текст на отдельные слова. Получим список всех слов текста. Используя процедуру, отработанную на одном из предыдущих этапов (при выполнении второго пункта данного задания), уберем незначащие слова из списка.\n",
    "Список будет включать все значащие слова,  причем столько раз, сколько имеется вхождений этого слова в исходный текст.\n",
    "Простым преобразованием можно получить множество всех слов текста, где по определению каждое слово входит только одина раз.\n",
    "Далее для каждого слова из множества, используя функции библиотеки spacy, можно найти в этом множестве список похожих на него слов. \n",
    "Эта процедура дает набор списков похожих слов, из которых состоит текст. Для каждого слова каждого списка можно найти количество его вхождений в очищенный текст. Взяв сумму числа вхождений для слов каждого списка, можно получить искомое число раз использования каждого слова в тексте.\n",
    "Чтобы не было путаницы с регистрами текста, предварительно можно привести весь текст к нижнему регистру.\n",
    "\n",
    "Тогда план работы по пункту 2 следующий.\n",
    "\n",
    "1. Загрузить текст из файла.\n",
    "2. Перевести текст в нижний регистр.\n",
    "3. Проходить строку, включающую исследуемый текст, знак за знаком, находить знак конца предложения, то есть точку, восклицательный или положительный знак, и его положение в тексте. Для точки проверять, чтобы справа и слева не было цифр, иначе это будет десятичная точка числа, а не знак конца предложения.\n",
    "4. Взяв слайс между предыдущим и текущим знаком конца предложения, проверить, есть ли в этом слайсе алфавитно-цифровые знаки. В случае наличия считаем полученный слайс очередным предложением текста. \n",
    "5. Далее из этого предложения создать новую строку, включающую только алфавитно-цифровые знаки, остальные знаки заменить пробелами. Затем расщепить полученную строку процедурой split и найти длину полученного списка. Это будет длина предложения, измеренная в словах. Пройдя таким образом все предложения текста, вывести  результат - список длин всех предложений - на экран.\n",
    "6. Убрать в тексте, полученном в пункте 2, знаки препинания и шире - все неалфавитные знаки, заменив их пробелами.\n",
    "7. Разбить текст на слова процедурой split, считая пробелы разделителями.\n",
    "8. Из полученного списка слов убрать все стоп-слова. Получить тем самым список значащих слов текста.\n",
    "9. Получить множество уникальных (пока без критерия схожести) слов текста, преобразовав список в множество.\n",
    "10. Загрузить модель spacy en_core_web_sm. Для каждого слова множества значащих с помощью данной модели найти схожие с ним слова и число их вхождений в очищенный текст. Также занести в словарь номер каждой группы схожих слов и число упоминаний слов данной группы.\n",
    "11. Отсортировать полученный словарь по значению ключа (дающего частотность соответствующей группы схожих слов)\n",
    "12. Отобрать 10 наиболее часто встречающихся групп слов в полученном словаре.\n",
    "14. Если в полученном словаре есть еще группы с той же частотностью, что и у десятой группы, также включить их в выводимый результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Загружаем текстовый файл:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read successfully\n"
     ]
    }
   ],
   "source": [
    "import string, spacy\n",
    "\n",
    "file_name = 'GospelJohn.txt' # file with text\n",
    "# file_name = 'example.txt' # file with text\n",
    "try:\n",
    "    f = open(file_name,\"r\") # open file for reading\n",
    "    text = f.read()         # reading file \n",
    "    f.close()               # closing file\n",
    "    print('Read successfully')\n",
    "except:\n",
    "    print('Error reading file!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Переводим текст в нижний регистр."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to lower case:\n",
    "text = text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Проходим строку, включающую исследуемый текст, знак за знаком, находим знак конца предложения, то есть точку, восклицательный или положительный знак, и его положение в тексте. Для точки проверяем, чтобы справа и слева не было цифр, иначе это будет десятичная точка числа, а не знак конца предложения.\n",
    "4. Взяв слайс между предыдущим и текущим знаком конца предложения, проверяем, есть ли в этом слайсе алфавитно-цифровые знаки. В случае наличия считаем полученный слайс очередным предложением текста. \n",
    "5. Далее из этого предложения создаем новую строку, включающую только алфавитно-цифровые знаки, остальные знаки заменяем пробелами. Затем расщепляем полученную строку процедурой split и находим длину полученного списка. Это будет длина предложения, измеренная в словах. Пройдя таким образом все предложения текста, выводим  результат - список длин всех предложений - на экран."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths of sentences in the text (in words):\n",
      " [17, 8, 17, 12, 12, 11, 19, 14, 14, 18, 11, 47, 30, 29, 12, 15, 24, 22, 13, 6, 3, 6, 4, 4, 8, 11, 5, 24, 9, 23, 38, 12, 24, 22, 21, 20, 41, 13, 26, 11, 14, 15, 7, 20, 16, 22, 6, 25, 18, 11, 29, 14, 7, 19, 8, 21, 19, 20, 7, 30]\n",
      "Number of sentences in the text:\n",
      " 60\n",
      "Average length of sentences in the text (in words):\n",
      " 16.7\n"
     ]
    }
   ],
   "source": [
    "# \"left\" - variable for left-hand end of a sentence\n",
    "right = -1 # variable for right-hand end of a sentence\n",
    "i = -1 # counter\n",
    "sentences_length_list = list() # list for sentences lengths\n",
    "for c in text:\n",
    "    i += 1\n",
    "    if c in \".?!\":\n",
    "        if c == '.' and text[i-1].isnumeric() and text[i+1].isnumeric():\n",
    "            continue\n",
    "        # new boundaries of a string:\n",
    "        left = right + 1\n",
    "        right = i\n",
    "        astring = text[left:right + 1] # extract the string\n",
    "        # print(f'String:\\n{astring}')\n",
    "        # if the string contains alphanumeric symbols, we suppose for it to be a sentence\n",
    "        if len([ch for ch in astring if ch.isalnum()]) > 0:\n",
    "            sentence_alphanumeric = \"\".join([ch if ch.isalnum else \" \" for ch in astring])\n",
    "            sentence_length = len(sentence_alphanumeric.split()) # length of sentence in words\n",
    "            sentences_length_list.append(sentence_length)\n",
    "print(f'Lengths of sentences in the text (in words):\\n {sentences_length_list}')\n",
    "print(f'Number of sentences in the text:\\n {len(sentences_length_list)}')\n",
    "print(f'Average length of sentences in the text (in words):\\n {round(sum(sentences_length_list) / len(sentences_length_list),1)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Убираем в тексте, полученном в пункте 2, знаки препинания и шире - все неалфавитные знаки, заменив их пробелами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace non-alphanumeric signs by whitespaces:\n",
    "text_no_signs = \"\".join([c if c.isalnum() else \" \" for c in text])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Разбиваем текст на слова процедурой split, считая пробелы разделителями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['in', 'the', 'beginning', 'was', 'the', 'word', 'and', 'the', 'word', 'was', 'with', 'god', 'and', 'the', 'word', 'was', 'god', 'the', 'same', 'was', 'in', 'the', 'beginning', 'with', 'god', 'all', 'things', 'were', 'made', 'by', 'him', 'and', 'without', 'him', 'was', 'not', 'any', 'thing', 'made', 'that', 'was', 'made', 'in', 'him', 'was', 'life', 'and', 'the', 'life', 'was', 'the', 'light', 'of', 'men', 'and', 'the', 'light', 'shineth', 'in', 'darkness', 'and', 'the', 'darkness', 'comprehended', 'it', 'not', 'there', 'was', 'a', 'man', 'sent', 'from', 'god', 'whose', 'name', 'was', 'john', 'the', 'same', 'came', 'for', 'a', 'witness', 'to', 'bear', 'witness', 'of', 'the', 'light', 'that', 'all', 'men', 'through', 'him', 'might', 'believe', 'he', 'was', 'not', 'that', 'light', 'but', 'was', 'sent', 'to', 'bear', 'witness', 'of', 'that', 'light', 'that', 'was', 'the', 'true', 'light', 'which', 'lighteth', 'every', 'man', 'that', 'cometh', 'into', 'the', 'world', 'he', 'was', 'in', 'the', 'world', 'and', 'the', 'world', 'was', 'made', 'by', 'him', 'and', 'the', 'world', 'knew', 'him', 'not', 'he', 'came', 'unto', 'his', 'own', 'and', 'his', 'own', 'received', 'him', 'not', 'but', 'as', 'many', 'as', 'received', 'him', 'to', 'them', 'gave', 'he', 'power', 'to', 'become', 'the', 'sons', 'of', 'god', 'even', 'to', 'them', 'that', 'believe', 'on', 'his', 'name', 'which', 'were', 'born', 'not', 'of', 'blood', 'nor', 'of', 'the', 'will', 'of', 'the', 'flesh', 'nor', 'of', 'the', 'will', 'of', 'man', 'but', 'of', 'god', 'and', 'the', 'word', 'was', 'made', 'flesh', 'and', 'dwelt', 'among', 'us', 'and', 'we', 'beheld', 'his', 'glory', 'the', 'glory', 'as', 'of', 'the', 'only', 'begotten', 'of', 'the', 'father', 'full', 'of', 'grace', 'and', 'truth', 'john', 'bare', 'witness', 'of', 'him', 'and', 'cried', 'saying', 'this', 'was', 'he', 'of', 'whom', 'i', 'spake', 'he', 'that', 'cometh', 'after', 'me', 'is', 'preferred', 'before', 'me', 'for', 'he', 'was', 'before', 'me', 'and', 'of', 'his', 'fulness', 'have', 'all', 'we', 'received', 'and', 'grace', 'for', 'grace', 'for', 'the', 'law', 'was', 'given', 'by', 'moses', 'but', 'grace', 'and', 'truth', 'came', 'by', 'jesus', 'christ', 'no', 'man', 'hath', 'seen', 'god', 'at', 'any', 'time', 'the', 'only', 'begotten', 'son', 'which', 'is', 'in', 'the', 'bosom', 'of', 'the', 'father', 'he', 'hath', 'declared', 'him', 'and', 'this', 'is', 'the', 'record', 'of', 'john', 'when', 'the', 'jews', 'sent', 'priests', 'and', 'levites', 'from', 'jerusalem', 'to', 'ask', 'him', 'who', 'art', 'thou', 'and', 'he', 'confessed', 'and', 'denied', 'not', 'but', 'confessed', 'i', 'am', 'not', 'the', 'christ', 'and', 'they', 'asked', 'him', 'what', 'then', 'art', 'thou', 'elias', 'and', 'he', 'saith', 'i', 'am', 'not', 'art', 'thou', 'that', 'prophet', 'and', 'he', 'answered', 'no', 'then', 'said', 'they', 'unto', 'him', 'who', 'art', 'thou', 'that', 'we', 'may', 'give', 'an', 'answer', 'to', 'them', 'that', 'sent', 'us', 'what', 'sayest', 'thou', 'of', 'thyself', 'he', 'said', 'i', 'am', 'the', 'voice', 'of', 'one', 'crying', 'in', 'the', 'wilderness', 'make', 'straight', 'the', 'way', 'of', 'the', 'lord', 'as', 'said', 'the', 'prophet', 'esaias', 'and', 'they', 'which', 'were', 'sent', 'were', 'of', 'the', 'pharisees', 'and', 'they', 'asked', 'him', 'and', 'said', 'unto', 'him', 'why', 'baptizest', 'thou', 'then', 'if', 'thou', 'be', 'not', 'that', 'christ', 'nor', 'elias', 'neither', 'that', 'prophet', 'john', 'answered', 'them', 'saying', 'i', 'baptize', 'with', 'water', 'but', 'there', 'standeth', 'one', 'among', 'you', 'whom', 'ye', 'know', 'not', 'he', 'it', 'is', 'who', 'coming', 'after', 'me', 'is', 'preferred', 'before', 'me', 'whose', 'shoe', 's', 'latchet', 'i', 'am', 'not', 'worthy', 'to', 'unloose', 'these', 'things', 'were', 'done', 'in', 'bethabara', 'beyond', 'jordan', 'where', 'john', 'was', 'baptizing', 'the', 'next', 'day', 'john', 'seeth', 'jesus', 'coming', 'unto', 'him', 'and', 'saith', 'behold', 'the', 'lamb', 'of', 'god', 'which', 'taketh', 'away', 'the', 'sin', 'of', 'the', 'world', 'this', 'is', 'he', 'of', 'whom', 'i', 'said', 'after', 'me', 'cometh', 'a', 'man', 'which', 'is', 'preferred', 'before', 'me', 'for', 'he', 'was', 'before', 'me', 'and', 'i', 'knew', 'him', 'not', 'but', 'that', 'he', 'should', 'be', 'made', 'manifest', 'to', 'israel', 'therefore', 'am', 'i', 'come', 'baptizing', 'with', 'water', 'and', 'john', 'bare', 'record', 'saying', 'i', 'saw', 'the', 'spirit', 'descending', 'from', 'heaven', 'like', 'a', 'dove', 'and', 'it', 'abode', 'upon', 'him', 'and', 'i', 'knew', 'him', 'not', 'but', 'he', 'that', 'sent', 'me', 'to', 'baptize', 'with', 'water', 'the', 'same', 'said', 'unto', 'me', 'upon', 'whom', 'thou', 'shalt', 'see', 'the', 'spirit', 'descending', 'and', 'remaining', 'on', 'him', 'the', 'same', 'is', 'he', 'which', 'baptizeth', 'with', 'the', 'holy', 'ghost', 'and', 'i', 'saw', 'and', 'bare', 'record', 'that', 'this', 'is', 'the', 'son', 'of', 'god', 'again', 'the', 'next', 'day', 'after', 'john', 'stood', 'and', 'two', 'of', 'his', 'disciples', 'and', 'looking', 'upon', 'jesus', 'as', 'he', 'walked', 'he', 'saith', 'behold', 'the', 'lamb', 'of', 'god', 'and', 'the', 'two', 'disciples', 'heard', 'him', 'speak', 'and', 'they', 'followed', 'jesus', 'then', 'jesus', 'turned', 'and', 'saw', 'them', 'following', 'and', 'saith', 'unto', 'them', 'what', 'seek', 'ye', 'they', 'said', 'unto', 'him', 'rabbi', 'which', 'is', 'to', 'say', 'being', 'interpreted', 'master', 'where', 'dwellest', 'thou', 'he', 'saith', 'unto', 'them', 'come', 'and', 'see', 'they', 'came', 'and', 'saw', 'where', 'he', 'dwelt', 'and', 'abode', 'with', 'him', 'that', 'day', 'for', 'it', 'was', 'about', 'the', 'tenth', 'hour', 'one', 'of', 'the', 'two', 'which', 'heard', 'john', 'speak', 'and', 'followed', 'him', 'was', 'andrew', 'simon', 'peter', 's', 'brother', 'he', 'first', 'findeth', 'his', 'own', 'brother', 'simon', 'and', 'saith', 'unto', 'him', 'we', 'have', 'found', 'the', 'messias', 'which', 'is', 'being', 'interpreted', 'the', 'christ', 'and', 'he', 'brought', 'him', 'to', 'jesus', 'and', 'when', 'jesus', 'beheld', 'him', 'he', 'said', 'thou', 'art', 'simon', 'the', 'son', 'of', 'jona', 'thou', 'shalt', 'be', 'called', 'cephas', 'which', 'is', 'by', 'interpretation', 'a', 'stone', 'the', 'day', 'following', 'jesus', 'would', 'go', 'forth', 'into', 'galilee', 'and', 'findeth', 'philip', 'and', 'saith', 'unto', 'him', 'follow', 'me', 'now', 'philip', 'was', 'of', 'bethsaida', 'the', 'city', 'of', 'andrew', 'and', 'peter', 'philip', 'findeth', 'nathanael', 'and', 'saith', 'unto', 'him', 'we', 'have', 'found', 'him', 'of', 'whom', 'moses', 'in', 'the', 'law', 'and', 'the', 'prophets', 'did', 'write', 'jesus', 'of', 'nazareth', 'the', 'son', 'of', 'joseph', 'and', 'nathanael', 'said', 'unto', 'him', 'can', 'there', 'any', 'good', 'thing', 'come', 'out', 'of', 'nazareth', 'philip', 'saith', 'unto', 'him', 'come', 'and', 'see', 'jesus', 'saw', 'nathanael', 'coming', 'to', 'him', 'and', 'saith', 'of', 'him', 'behold', 'an', 'israelite', 'indeed', 'in', 'whom', 'is', 'no', 'guile', 'nathanael', 'saith', 'unto', 'him', 'whence', 'knowest', 'thou', 'me', 'jesus', 'answered', 'and', 'said', 'unto', 'him', 'before', 'that', 'philip', 'called', 'thee', 'when', 'thou', 'wast', 'under', 'the', 'fig', 'tree', 'i', 'saw', 'thee', 'nathanael', 'answered', 'and', 'saith', 'unto', 'him', 'rabbi', 'thou', 'art', 'the', 'son', 'of', 'god', 'thou', 'art', 'the', 'king', 'of', 'israel', 'jesus', 'answered', 'and', 'said', 'unto', 'him', 'because', 'i', 'said', 'unto', 'thee', 'i', 'saw', 'thee', 'under', 'the', 'fig', 'tree', 'believest', 'thou', 'thou', 'shalt', 'see', 'greater', 'things', 'than', 'these', 'and', 'he', 'saith', 'unto', 'him', 'verily', 'verily', 'i', 'say', 'unto', 'you', 'hereafter', 'ye', 'shall', 'see', 'heaven', 'open', 'and', 'the', 'angels', 'of', 'god', 'ascending', 'and', 'descending', 'upon', 'the', 'son', 'of', 'man']\n"
     ]
    }
   ],
   "source": [
    "word_list = text_no_signs.split() # split text into words and put to the list\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Из полученного списка слов убираем все стоп-слова. Получаем тем самым список значащих слов текста.\n",
    "\n",
    "Для этого надо вначале создать список стоп-слов\n",
    "(источник: https://github.com/explosion/spaCy/blob/master/spacy/lang/en/stop_words.py)\n",
    "Также мы немного расширяем этот список для учета устаревших вариантов слов, фигурирующих в нашем тексте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hundred', 'everyone', 'alone', 'everywhere', 'myself', 'see', 'until', 'between', '’d', 'fifty', 'on', 'it', 'indeed', 'namely', 'very', 'most', 'becoming', 'so', 'becomes', 'are', 'besides', 'you', 'moreover', 'about', 'many', 'each', 'am', 'as', 'too', 'whose', 'who', 'me', 'while', 'put', 'top', 'just', 'in', 'their', 'whither', 'whereafter', 'being', 'art', 'and', 'throughout', \"n't\", 'keep', 'sometimes', 'really', 'he', 'two', 'empty', '’ll', 'third', 'ever', 'even', '‘re', 'first', 'three', 'mostly', 'few', 'unless', 'anyhow', 'thereafter', 'mine', 'noone', 'n‘t', 'beside', 'still', 'that', 'thereby', 'should', \"'m\", 'since', 'did', 'up', 'move', 'whatever', 'ya', 'never', 'her', 'where', 'one', '‘s', 'often', 'can', 'amongst', '’ve', 'us', 'yet', 'afterwards', '‘d', 'into', 'doing', \"'d\", 'else', 'around', 'however', 'meanwhile', 'none', 'whereupon', 'himself', 'others', 'became', 'before', 'nobody', 'because', '’re', '‘ll', 'five', 'call', 'its', 'they', 'back', 'full', 'every', 'his', 'bottom', 'four', 'latter', 'enough', 'thru', 'fifteen', 'the', 'only', 'forty', 'were', 'unto', 'now', 'why', 'beforehand', 'yours', 'done', 'shalt', \"'ve\", 'somehow', '’s', 'off', 'above', 'n’t', 'together', 'ourselves', 'formerly', 'what', 'had', 'will', 'upon', 'give', 'twenty', 'twelve', 'not', 'through', 'towards', '‘ve', 'whole', 'when', 'former', 'have', 'neither', 'once', 'hereafter', 'though', 'must', 'further', 'also', 'latterly', 'both', 'somewhere', 'whoever', 'thereupon', 'does', 'more', 'at', 'thou', 'we', 'without', 'wherein', 'make', 'six', 'last', 'otherwise', 'be', 'whom', 'another', 'except', 'my', 'may', 'eleven', 'under', 'sixty', 'due', 'whereby', 'say', 'own', 'than', 'anything', 'always', 'there', 'no', 'someone', 'well', 'nothing', 'next', \"'ll\", 'or', 'beyond', 'him', 'seemed', 'wherever', 'please', 'after', 'hath', \"'re\", 'yourselves', 'an', 'regarding', 'get', 're', 'either', 'how', 'onto', 'during', 'then', 'made', 'via', '‘m', 'thee', 'using', 'seem', 'elsewhere', 'might', '’m', 'much', 'all', 'ten', 'eight', 'some', 'against', 'whenever', 'out', 'was', 'anywhere', 'hereby', 'used', 'if', 'our', 'nine', 'whence', 'various', 'sometime', 'hence', 'therefore', 'from', 'nowhere', 'become', 'amount', 'rather', 'seeming', 'thence', 'yourself', 'a', 'serious', 'your', 'd', 'among', 'but', 'almost', 'she', 'below', 'everything', 'whereas', 'themselves', 'across', 'to', 's', 'itself', 'i', 'hers', 'of', 'perhaps', 'over', 'go', 'same', 'again', 'front', 'thyself', 'ca', 'seems', 'thus', 'name', 'here', 'other', 'take', 'anyone', 'ours', 'toward', 'such', 'within', 'do', 'them', 'along', 'these', 'quite', 'nt', 'behind', 'whether', 'with', 'part', 'herein', 'anyway', 'least', 'by', 'less', 'nor', 'although', 'per', 'hereupon', \"'s\", 'could', 'therein', 'has', 've', 'been', 'which', 'would', 'this', 'any', 'show', 'already', 'm', 'down', 'side', 'something', 'several', 'nevertheless', 'for', 'is', 'those', 'cannot', 'ye', 'll', 'herself'}\n"
     ]
    }
   ],
   "source": [
    "STOP_WORDS = set(\n",
    "    \"\"\"\n",
    "a about above across after afterwards again against all almost alone along\n",
    "already also although always am among amongst amount an and another any anyhow\n",
    "anyone anything anyway anywhere are around as at\n",
    "\n",
    "back be became because become becomes becoming been before beforehand behind\n",
    "being below beside besides between beyond both bottom but by\n",
    "\n",
    "call can cannot ca could\n",
    "\n",
    "did do does doing done down due during\n",
    "\n",
    "each eight either eleven else elsewhere empty enough even ever every\n",
    "everyone everything everywhere except\n",
    "\n",
    "few fifteen fifty first five for former formerly forty four from front full\n",
    "further\n",
    "\n",
    "get give go\n",
    "\n",
    "had has have he hence her here hereafter hereby herein hereupon hers herself\n",
    "him himself his how however hundred\n",
    "\n",
    "i if in indeed into is it its itself\n",
    "\n",
    "keep\n",
    "\n",
    "last latter latterly least less\n",
    "\n",
    "just\n",
    "\n",
    "made make many may me meanwhile might mine more moreover most mostly move much\n",
    "must my myself\n",
    "\n",
    "name namely neither never nevertheless next nine no nobody none noone nor not\n",
    "nothing now nowhere\n",
    "\n",
    "of off often on once one only onto or other others otherwise our ours ourselves\n",
    "out over own\n",
    "\n",
    "part per perhaps please put\n",
    "\n",
    "quite\n",
    "\n",
    "rather re really regarding\n",
    "\n",
    "s same say see seem seemed seeming seems serious several she should show side\n",
    "since six sixty so some somehow someone something sometime sometimes somewhere\n",
    "still such \n",
    "\n",
    "take ten than that the their them themselves then thence there thereafter\n",
    "thereby therefore therein thereupon these they third this those though three\n",
    "through throughout thru thus to together too top toward towards twelve twenty\n",
    "two\n",
    "\n",
    "under until up unless upon us used using\n",
    "\n",
    "various very very via was we well were what whatever when whence whenever where\n",
    "whereafter whereas whereby wherein whereupon wherever whether which while\n",
    "whither who whoever whole whom whose why will with within without would\n",
    "\n",
    "yet you your yours yourself yourselves\n",
    "\"\"\".split()\n",
    ")\n",
    "\n",
    "contractions = [\"n't\", \"nt\", \"'d\", \"d\", \"'ll\", \"ll\", \"'m\", \"m\", \"'re\", \"re\", \"'s\", \"s\", \"'ve\", \"ve\"]\n",
    "STOP_WORDS.update(contractions)\n",
    "\n",
    "for apostrophe in [\"‘\", \"’\"]:\n",
    "    for stopword in contractions:\n",
    "        STOP_WORDS.add(stopword.replace(\"'\", apostrophe))\n",
    "\n",
    "obsoletisms = [\"art\", \"hath\", \"shalt\", \"thou\", \"thee\", \"thyself\", \"ye\", \"ya\", \"unto\"] # obsolete word forms\n",
    "STOP_WORDS.update(obsoletisms)\n",
    "\n",
    "print(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Продолжение п.8. \n",
    "Убираем из списка слова, если они входят в список стоп-слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['beginning', 'word', 'word', 'god', 'word', 'god', 'beginning', 'god', 'things', 'thing', 'life', 'life', 'light', 'men', 'light', 'shineth', 'darkness', 'darkness', 'comprehended', 'man', 'sent', 'god', 'john', 'came', 'witness', 'bear', 'witness', 'light', 'men', 'believe', 'light', 'sent', 'bear', 'witness', 'light', 'true', 'light', 'lighteth', 'man', 'cometh', 'world', 'world', 'world', 'world', 'knew', 'came', 'received', 'received', 'gave', 'power', 'sons', 'god', 'believe', 'born', 'blood', 'flesh', 'man', 'god', 'word', 'flesh', 'dwelt', 'beheld', 'glory', 'glory', 'begotten', 'father', 'grace', 'truth', 'john', 'bare', 'witness', 'cried', 'saying', 'spake', 'cometh', 'preferred', 'fulness', 'received', 'grace', 'grace', 'law', 'given', 'moses', 'grace', 'truth', 'came', 'jesus', 'christ', 'man', 'seen', 'god', 'time', 'begotten', 'son', 'bosom', 'father', 'declared', 'record', 'john', 'jews', 'sent', 'priests', 'levites', 'jerusalem', 'ask', 'confessed', 'denied', 'confessed', 'christ', 'asked', 'elias', 'saith', 'prophet', 'answered', 'said', 'answer', 'sent', 'sayest', 'said', 'voice', 'crying', 'wilderness', 'straight', 'way', 'lord', 'said', 'prophet', 'esaias', 'sent', 'pharisees', 'asked', 'said', 'baptizest', 'christ', 'elias', 'prophet', 'john', 'answered', 'saying', 'baptize', 'water', 'standeth', 'know', 'coming', 'preferred', 'shoe', 'latchet', 'worthy', 'unloose', 'things', 'bethabara', 'jordan', 'john', 'baptizing', 'day', 'john', 'seeth', 'jesus', 'coming', 'saith', 'behold', 'lamb', 'god', 'taketh', 'away', 'sin', 'world', 'said', 'cometh', 'man', 'preferred', 'knew', 'manifest', 'israel', 'come', 'baptizing', 'water', 'john', 'bare', 'record', 'saying', 'saw', 'spirit', 'descending', 'heaven', 'like', 'dove', 'abode', 'knew', 'sent', 'baptize', 'water', 'said', 'spirit', 'descending', 'remaining', 'baptizeth', 'holy', 'ghost', 'saw', 'bare', 'record', 'son', 'god', 'day', 'john', 'stood', 'disciples', 'looking', 'jesus', 'walked', 'saith', 'behold', 'lamb', 'god', 'disciples', 'heard', 'speak', 'followed', 'jesus', 'jesus', 'turned', 'saw', 'following', 'saith', 'seek', 'said', 'rabbi', 'interpreted', 'master', 'dwellest', 'saith', 'come', 'came', 'saw', 'dwelt', 'abode', 'day', 'tenth', 'hour', 'heard', 'john', 'speak', 'followed', 'andrew', 'simon', 'peter', 'brother', 'findeth', 'brother', 'simon', 'saith', 'found', 'messias', 'interpreted', 'christ', 'brought', 'jesus', 'jesus', 'beheld', 'said', 'simon', 'son', 'jona', 'called', 'cephas', 'interpretation', 'stone', 'day', 'following', 'jesus', 'forth', 'galilee', 'findeth', 'philip', 'saith', 'follow', 'philip', 'bethsaida', 'city', 'andrew', 'peter', 'philip', 'findeth', 'nathanael', 'saith', 'found', 'moses', 'law', 'prophets', 'write', 'jesus', 'nazareth', 'son', 'joseph', 'nathanael', 'said', 'good', 'thing', 'come', 'nazareth', 'philip', 'saith', 'come', 'jesus', 'saw', 'nathanael', 'coming', 'saith', 'behold', 'israelite', 'guile', 'nathanael', 'saith', 'knowest', 'jesus', 'answered', 'said', 'philip', 'called', 'wast', 'fig', 'tree', 'saw', 'nathanael', 'answered', 'saith', 'rabbi', 'son', 'god', 'king', 'israel', 'jesus', 'answered', 'said', 'said', 'saw', 'fig', 'tree', 'believest', 'greater', 'things', 'saith', 'verily', 'verily', 'shall', 'heaven', 'open', 'angels', 'god', 'ascending', 'descending', 'son', 'man']\n"
     ]
    }
   ],
   "source": [
    "word_list_new = list()\n",
    "for aword in word_list:\n",
    "    if aword not in STOP_WORDS:\n",
    "        word_list_new.append(aword)\n",
    "\n",
    "word_list = word_list_new\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Получаем множество уникальных (пока без критерия схожести) слов текста, преобразовав список в множество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wast', 'latchet', 'cried', 'bear', 'stood', 'word', 'city', 'dwellest', 'moses', 'tree', 'know', 'saith', 'confessed', 'philip', 'remaining', 'tenth', 'interpreted', 'fulness', 'grace', 'said', 'spake', 'time', 'followed', 'dove', 'angels', 'shoe', 'walked', 'gave', 'father', 'like', 'beheld', 'holy', 'answer', 'law', 'messias', 'nazareth', 'knowest', 'saying', 'baptize', 'galilee', 'follow', 'beginning', 'true', 'ascending', 'bosom', 'denied', 'stone', 'dwelt', 'lord', 'master', 'nathanael', 'knew', 'man', 'jesus', 'flesh', 'elias', 'abode', 'joseph', 'life', 'record', 'bare', 'glory', 'heaven', 'prophets', 'following', 'found', 'darkness', 'straight', 'power', 'cometh', 'esaias', 'baptizeth', 'christ', 'jews', 'day', 'declared', 'seen', 'worthy', 'brought', 'preferred', 'way', 'jordan', 'answered', 'shall', 'israel', 'sent', 'believe', 'voice', 'crying', 'bethabara', 'interpretation', 'king', 'guile', 'levites', 'baptizing', 'lamb', 'hour', 'behold', 'water', 'taketh', 'verily', 'born', 'prophet', 'truth', 'ghost', 'given', 'sin', 'world', 'disciples', 'heard', 'baptizest', 'came', 'good', 'away', 'standeth', 'thing', 'looking', 'manifest', 'witness', 'begotten', 'greater', 'unloose', 'comprehended', 'light', 'turned', 'sayest', 'findeth', 'believest', 'forth', 'lighteth', 'write', 'john', 'andrew', 'called', 'seek', 'brother', 'received', 'god', 'come', 'jerusalem', 'son', 'bethsaida', 'speak', 'spirit', 'peter', 'ask', 'wilderness', 'sons', 'blood', 'shineth', 'pharisees', 'rabbi', 'jona', 'men', 'israelite', 'coming', 'asked', 'priests', 'fig', 'simon', 'saw', 'open', 'seeth', 'things', 'cephas', 'descending'}\n"
     ]
    }
   ],
   "source": [
    "word_set = set(word_list)\n",
    "print(word_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Загружаем модель spacy en_core_web_sm. \n",
    "Для каждого слова множества значащих с помощью данной модели находим схожие с ним слова и число их вхождений в очищенный текст. \n",
    "Эти похожие слова заносим в список проверенных слов, чтобы на следующей итерации не считать их снова.\n",
    "Повторяем для каждого следующего слова из множества значащих слов.\n",
    "Попутно заносим в словарь номер каждой группы схожих слов и число упоминаний слов данной группы.\n",
    "Выводим на экран группы схожих слов и число упоминаний слов этой группы в тексте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking wast and wast\n",
      "wast\n",
      "Number of these words in the text:\n",
      " 1\n",
      "\n",
      "\n",
      "Number of these words in the text:\n",
      " 0\n",
      "\n",
      "Checking cried and came\n",
      "Checking cried and knew\n",
      "Checking cried and came\n",
      "Checking cried and gave\n",
      "Checking cried and cried\n",
      "Checking cried and came\n",
      "Checking cried and asked\n",
      "Checking cried and said\n",
      "Checking cried and said\n",
      "Checking cried and said\n",
      "Checking cried and asked\n",
      "Checking cried and said\n",
      "Checking cried and said\n",
      "Checking cried and knew\n",
      "Checking cried and saw\n",
      "Checking cried and knew\n",
      "Checking cried and said\n",
      "Checking cried and saw\n",
      "Checking cried and stood\n",
      "Checking cried and walked\n",
      "Checking cried and heard\n",
      "Checking cried and turned\n",
      "Checking cried and saw\n",
      "Checking cried and said\n",
      "Checking cried and came\n",
      "Checking cried and saw\n",
      "Checking cried and heard\n",
      "Checking cried and said\n",
      "Checking cried and said\n",
      "Checking cried and saw\n",
      "Checking cried and said\n",
      "Checking cried and saw\n",
      "Checking cried and said\n",
      "Checking cried and said\n",
      "Checking cried and saw\n",
      "gave, came, asked, cried, turned, stood, saw, knew, heard, said, walked\n",
      "Number of these words in the text:\n",
      " 35\n",
      "\n",
      "Checking bear and bear\n",
      "Checking bear and bear\n",
      "bear\n",
      "Number of these words in the text:\n",
      " 2\n",
      "\n",
      "Checking word and word\n",
      "Checking word and word\n",
      "Checking word and word\n",
      "Checking word and word\n",
      "word\n",
      "Number of these words in the text:\n",
      " 4\n",
      "\n",
      "Checking city and city\n",
      "city\n",
      "Number of these words in the text:\n",
      " 1\n",
      "\n",
      "\n",
      "Number of these words in the text:\n",
      " 0\n",
      "\n",
      "Checking moses and moses\n",
      "Checking moses and elias\n",
      "Checking moses and elias\n",
      "Checking moses and moses\n",
      "moses, elias\n",
      "Number of these words in the text:\n",
      " 4\n",
      "\n",
      "Checking tree and tree\n",
      "Checking tree and tree\n",
      "tree\n",
      "Number of these words in the text:\n",
      " 2\n",
      "\n",
      "Checking know and things\n",
      "Checking know and thing\n",
      "Checking know and time\n",
      "Checking know and straight\n",
      "Checking know and way\n",
      "Checking know and know\n",
      "Checking know and things\n",
      "Checking know and come\n",
      "Checking know and come\n",
      "Checking know and called\n",
      "Checking know and good\n",
      "Checking know and thing\n",
      "Checking know and come\n",
      "Checking know and come\n",
      "Checking know and called\n",
      "Checking know and things\n",
      "good, called, thing, come, straight, things, way, know, time\n",
      "Number of these words in the text:\n",
      " 16\n",
      "\n",
      "Checking saith and cometh\n",
      "Checking saith and spake\n",
      "Checking saith and cometh\n",
      "Checking saith and fulness\n",
      "Checking saith and saith\n",
      "Checking saith and prophet\n",
      "Checking saith and prophet\n",
      "Checking saith and prophet\n",
      "Checking saith and saith\n",
      "Checking saith and behold\n",
      "Checking saith and cometh\n",
      "Checking saith and holy\n",
      "Checking saith and disciples\n",
      "Checking saith and saith\n",
      "Checking saith and behold\n",
      "Checking saith and disciples\n",
      "Checking saith and saith\n",
      "Checking saith and saith\n",
      "Checking saith and saith\n",
      "Checking saith and forth\n",
      "Checking saith and saith\n",
      "Checking saith and saith\n",
      "Checking saith and prophets\n",
      "Checking saith and saith\n",
      "Checking saith and saith\n",
      "Checking saith and behold\n",
      "Checking saith and saith\n",
      "Checking saith and saith\n",
      "Checking saith and saith\n",
      "Checking saith and verily\n",
      "Checking saith and verily\n",
      "verily, saith, forth, prophets, holy, cometh, disciples, behold, fulness, spake, prophet\n",
      "Number of these words in the text:\n",
      " 31\n",
      "\n",
      "Checking confessed and confessed\n",
      "Checking confessed and confessed\n",
      "confessed\n",
      "Number of these words in the text:\n",
      " 2\n",
      "\n",
      "Checking philip and philip\n",
      "Checking philip and philip\n",
      "Checking philip and philip\n",
      "Checking philip and philip\n",
      "Checking philip and philip\n",
      "philip\n",
      "Number of these words in the text:\n",
      " 5\n",
      "\n",
      "Checking remaining and given\n",
      "Checking remaining and remaining\n",
      "remaining, given\n",
      "Number of these words in the text:\n",
      " 2\n",
      "\n",
      "Checking tenth and tenth\n",
      "tenth\n",
      "Number of these words in the text:\n",
      " 1\n",
      "\n",
      "Checking interpreted and declared\n",
      "Checking interpreted and interpreted\n",
      "Checking interpreted and interpreted\n",
      "declared, interpreted\n",
      "Number of these words in the text:\n",
      " 3\n",
      "\n",
      "Checking grace and glory\n",
      "Checking grace and glory\n",
      "Checking grace and grace\n",
      "Checking grace and grace\n",
      "Checking grace and grace\n",
      "Checking grace and grace\n",
      "Checking grace and heaven\n",
      "Checking grace and heaven\n",
      "heaven, glory, grace\n",
      "Number of these words in the text:\n",
      " 8\n",
      "\n",
      "Checking followed and followed\n",
      "Checking followed and followed\n",
      "Checking followed and brought\n",
      "brought, followed\n",
      "Number of these words in the text:\n",
      " 3\n",
      "\n",
      "Checking dove and dove\n",
      "dove\n",
      "Number of these words in the text:\n",
      " 1\n",
      "\n",
      "Checking angels and manifest\n",
      "Checking angels and angels\n",
      "angels, manifest\n",
      "Number of these words in the text:\n",
      " 2\n",
      "\n",
      "Checking shoe and shoe\n",
      "Checking shoe and jordan\n",
      "jordan, shoe\n",
      "Number of these words in the text:\n",
      " 2\n",
      "\n",
      "Checking father and father\n",
      "Checking father and father\n",
      "father\n",
      "Number of these words in the text:\n",
      " 2\n",
      "\n",
      "Checking like and like\n",
      "like\n",
      "Number of these words in the text:\n",
      " 1\n",
      "\n",
      "Checking beheld and beheld\n",
      "Checking beheld and beheld\n",
      "beheld\n",
      "Number of these words in the text:\n",
      " 2\n",
      "\n",
      "Checking answer and ask\n",
      "Checking answer and answered\n",
      "Checking answer and answer\n",
      "Checking answer and answered\n",
      "Checking answer and write\n",
      "Checking answer and answered\n",
      "Checking answer and answered\n",
      "Checking answer and answered\n",
      "ask, answer, write, answered\n",
      "Number of these words in the text:\n",
      " 8\n",
      "\n",
      "Checking law and law\n",
      "Checking law and law\n",
      "law\n",
      "Number of these words in the text:\n",
      " 2\n",
      "\n",
      "Checking messias and messias\n",
      "messias\n",
      "Number of these words in the text:\n",
      " 1\n",
      "\n",
      "Checking nazareth and nazareth\n",
      "Checking nazareth and nazareth\n",
      "nazareth\n",
      "Number of these words in the text:\n",
      " 2\n",
      "\n",
      "Checking knowest and sayest\n",
      "Checking knowest and knowest\n",
      "sayest, knowest\n",
      "Number of these words in the text:\n",
      " 2\n",
      "\n",
      "Checking saying and saying\n",
      "Checking saying and saying\n",
      "Checking saying and saying\n",
      "saying\n",
      "Number of these words in the text:\n",
      " 3\n",
      "\n",
      "Checking baptize and baptize\n",
      "Checking baptize and baptizing\n",
      "Checking baptize and baptizing\n",
      "Checking baptize and baptize\n",
      "baptize, baptizing\n",
      "Number of these words in the text:\n",
      " 4\n",
      "\n",
      "Checking galilee and galilee\n",
      "galilee\n",
      "Number of these words in the text:\n",
      " 1\n",
      "\n",
      "Checking follow and sent\n",
      "Checking follow and sent\n",
      "Checking follow and sent\n",
      "Checking follow and sent\n",
      "Checking follow and sent\n",
      "Checking follow and sent\n",
      "Checking follow and speak\n",
      "Checking follow and seek\n",
      "Checking follow and speak\n",
      "Checking follow and follow\n",
      "follow, speak, sent, seek\n",
      "Number of these words in the text:\n",
      " 10\n",
      "\n",
      "Checking beginning and beginning\n",
      "Checking beginning and beginning\n",
      "beginning\n",
      "Number of these words in the text:\n",
      " 2\n",
      "\n",
      "Checking true and true\n",
      "Checking true and looking\n",
      "looking, true\n",
      "Number of these words in the text:\n",
      " 2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varaksa_yua\\AppData\\Local\\Temp\\ipykernel_8376\\4060061897.py:17: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  if w.has_vector and aword_nlp.similarity(w) > 0.9:  # checking for similarity; 0.x is similarity threshold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking ascending and descending\n",
      "Checking ascending and descending\n",
      "Checking ascending and ascending\n",
      "Checking ascending and descending\n",
      "descending, ascending\n",
      "Number of these words in the text:\n",
      " 4\n",
      "\n",
      "Checking bosom and bosom\n",
      "bosom\n",
      "Number of these words in the text:\n",
      " 1\n",
      "\n",
      "Checking denied and denied\n",
      "denied\n",
      "Number of these words in the text:\n",
      " 1\n",
      "\n",
      "Checking stone and stone\n",
      "stone\n",
      "Number of these words in the text:\n",
      " 1\n",
      "\n",
      "Checking dwelt and dwelt\n",
      "Checking dwelt and begotten\n",
      "Checking dwelt and begotten\n",
      "Checking dwelt and taketh\n",
      "Checking dwelt and dwelt\n",
      "dwelt, taketh, begotten\n",
      "Number of these words in the text:\n",
      " 5\n",
      "\n",
      "Checking lord and darkness\n",
      "Checking lord and darkness\n",
      "Checking lord and lord\n",
      "Checking lord and sin\n",
      "Checking lord and ghost\n",
      "Checking lord and king\n",
      "king, ghost, sin, darkness, lord\n",
      "Number of these words in the text:\n",
      " 6\n",
      "\n",
      "Checking master and master\n",
      "master\n",
      "Number of these words in the text:\n",
      " 1\n",
      "\n",
      "Checking nathanael and nathanael\n",
      "Checking nathanael and nathanael\n",
      "Checking nathanael and nathanael\n",
      "Checking nathanael and nathanael\n",
      "Checking nathanael and nathanael\n",
      "nathanael\n",
      "Number of these words in the text:\n",
      " 5\n",
      "\n",
      "Checking man and man\n",
      "Checking man and man\n",
      "Checking man and sons\n",
      "Checking man and man\n",
      "Checking man and man\n",
      "Checking man and son\n",
      "Checking man and man\n",
      "Checking man and son\n",
      "Checking man and son\n",
      "Checking man and son\n",
      "Checking man and son\n",
      "Checking man and son\n",
      "Checking man and man\n",
      "man, sons, son\n",
      "Number of these words in the text:\n",
      " 13\n",
      "\n",
      "Checking jesus and jesus\n",
      "Checking jesus and christ\n",
      "Checking jesus and priests\n",
      "Checking jesus and christ\n",
      "Checking jesus and pharisees\n",
      "Checking jesus and christ\n",
      "Checking jesus and jesus\n",
      "Checking jesus and jesus\n",
      "Checking jesus and jesus\n",
      "Checking jesus and jesus\n",
      "Checking jesus and christ\n",
      "Checking jesus and jesus\n",
      "Checking jesus and jesus\n",
      "Checking jesus and jesus\n",
      "Checking jesus and jesus\n",
      "Checking jesus and jesus\n",
      "Checking jesus and jesus\n",
      "Checking jesus and jesus\n",
      "christ, pharisees, jesus, priests\n",
      "Number of these words in the text:\n",
      " 18\n",
      "\n",
      "Checking flesh and flesh\n",
      "Checking flesh and flesh\n",
      "flesh\n",
      "Number of these words in the text:\n",
      " 2\n",
      "\n",
      "Checking abode and abode\n",
      "Checking abode and abode\n",
      "abode\n",
      "Number of these words in the text:\n",
      " 2\n",
      "\n",
      "Checking joseph and john\n",
      "Checking joseph and john\n",
      "Checking joseph and john\n",
      "Checking joseph and john\n",
      "Checking joseph and john\n",
      "Checking joseph and john\n",
      "Checking joseph and john\n",
      "Checking joseph and john\n",
      "Checking joseph and john\n",
      "Checking joseph and andrew\n",
      "Checking joseph and simon\n",
      "Checking joseph and peter\n",
      "Checking joseph and simon\n",
      "Checking joseph and simon\n",
      "Checking joseph and andrew\n",
      "Checking joseph and peter\n",
      "Checking joseph and joseph\n",
      "joseph, simon, john, andrew, peter\n",
      "Number of these words in the text:\n",
      " 17\n",
      "\n",
      "Checking life and life\n",
      "Checking life and life\n",
      "Checking life and world\n",
      "Checking life and world\n",
      "Checking life and world\n",
      "Checking life and world\n",
      "Checking life and world\n",
      "Checking life and spirit\n",
      "Checking life and spirit\n",
      "world, life, spirit\n",
      "Number of these words in the text:\n",
      " 9\n",
      "\n",
      "Checking record and record\n",
      "Checking record and record\n",
      "Checking record and record\n",
      "record\n",
      "Number of these words in the text:\n",
      " 3\n",
      "\n",
      "Checking bare and bare\n",
      "Checking bare and bare\n",
      "Checking bare and bare\n",
      "bare\n",
      "Number of these words in the text:\n",
      " 3\n",
      "\n",
      "Checking following and following\n",
      "Checking following and following\n",
      "following\n",
      "Number of these words in the text:\n",
      " 2\n",
      "\n",
      "Checking found and found\n",
      "Checking found and found\n",
      "found\n",
      "Number of these words in the text:\n",
      " 2\n",
      "\n",
      "Checking power and power\n",
      "power\n",
      "Number of these words in the text:\n",
      " 1\n",
      "\n",
      "\n",
      "Number of these words in the text:\n",
      " 0\n",
      "\n",
      "\n",
      "Number of these words in the text:\n",
      " 0\n",
      "\n",
      "Checking jews and jews\n",
      "Checking jews and rabbi\n",
      "Checking jews and rabbi\n",
      "jews, rabbi\n",
      "Number of these words in the text:\n",
      " 3\n",
      "\n",
      "Checking day and day\n",
      "Checking day and day\n",
      "Checking day and day\n",
      "Checking day and day\n",
      "day\n",
      "Number of these words in the text:\n",
      " 4\n",
      "\n",
      "Checking seen and seen\n",
      "Checking seen and coming\n",
      "Checking seen and coming\n",
      "Checking seen and coming\n",
      "seen, coming\n",
      "Number of these words in the text:\n",
      " 4\n",
      "\n",
      "Checking worthy and worthy\n",
      "worthy\n",
      "Number of these words in the text:\n",
      " 1\n",
      "\n",
      "Checking preferred and preferred\n",
      "Checking preferred and preferred\n",
      "Checking preferred and preferred\n",
      "preferred\n",
      "Number of these words in the text:\n",
      " 3\n",
      "\n",
      "Checking shall and shall\n",
      "shall\n",
      "Number of these words in the text:\n",
      " 1\n",
      "\n",
      "Checking israel and jerusalem\n",
      "Checking israel and israel\n",
      "Checking israel and israel\n",
      "jerusalem, israel\n",
      "Number of these words in the text:\n",
      " 3\n",
      "\n",
      "Checking believe and believe\n",
      "Checking believe and believe\n",
      "believe\n",
      "Number of these words in the text:\n",
      " 2\n",
      "\n",
      "Checking voice and voice\n",
      "voice\n",
      "Number of these words in the text:\n",
      " 1\n",
      "\n",
      "Checking crying and crying\n",
      "crying\n",
      "Number of these words in the text:\n",
      " 1\n",
      "\n",
      "\n",
      "Number of these words in the text:\n",
      " 0\n",
      "\n",
      "Checking interpretation and interpretation\n",
      "interpretation\n",
      "Number of these words in the text:\n",
      " 1\n",
      "\n",
      "Checking guile and guile\n",
      "guile\n",
      "Number of these words in the text:\n",
      " 1\n",
      "\n",
      "Checking levites and levites\n",
      "levites\n",
      "Number of these words in the text:\n",
      " 1\n",
      "\n",
      "Checking lamb and lamb\n",
      "Checking lamb and lamb\n",
      "lamb\n",
      "Number of these words in the text:\n",
      " 2\n",
      "\n",
      "Checking hour and hour\n",
      "hour\n",
      "Number of these words in the text:\n",
      " 1\n",
      "\n",
      "Checking water and water\n",
      "Checking water and water\n",
      "Checking water and water\n",
      "water\n",
      "Number of these words in the text:\n",
      " 3\n",
      "\n",
      "Checking born and born\n",
      "born\n",
      "Number of these words in the text:\n",
      " 1\n",
      "\n",
      "Checking truth and truth\n",
      "Checking truth and truth\n",
      "truth\n",
      "Number of these words in the text:\n",
      " 2\n",
      "\n",
      "\n",
      "Number of these words in the text:\n",
      " 0\n",
      "\n",
      "Checking away and away\n",
      "away\n",
      "Number of these words in the text:\n",
      " 1\n",
      "\n",
      "Checking standeth and standeth\n",
      "standeth\n",
      "Number of these words in the text:\n",
      " 1\n",
      "\n",
      "Checking witness and witness\n",
      "Checking witness and witness\n",
      "Checking witness and witness\n",
      "Checking witness and witness\n",
      "witness\n",
      "Number of these words in the text:\n",
      " 4\n",
      "\n",
      "Checking greater and greater\n",
      "greater\n",
      "Number of these words in the text:\n",
      " 1\n",
      "\n",
      "\n",
      "Number of these words in the text:\n",
      " 0\n",
      "\n",
      "Checking comprehended and comprehended\n",
      "comprehended\n",
      "Number of these words in the text:\n",
      " 1\n",
      "\n",
      "Checking light and light\n",
      "Checking light and light\n",
      "Checking light and light\n",
      "Checking light and light\n",
      "Checking light and light\n",
      "Checking light and light\n",
      "light\n",
      "Number of these words in the text:\n",
      " 6\n",
      "\n",
      "Checking findeth and findeth\n",
      "Checking findeth and findeth\n",
      "Checking findeth and findeth\n",
      "findeth\n",
      "Number of these words in the text:\n",
      " 3\n",
      "\n",
      "\n",
      "Number of these words in the text:\n",
      " 0\n",
      "\n",
      "\n",
      "Number of these words in the text:\n",
      " 0\n",
      "\n",
      "Checking brother and brother\n",
      "Checking brother and brother\n",
      "brother\n",
      "Number of these words in the text:\n",
      " 2\n",
      "\n",
      "Checking received and received\n",
      "Checking received and received\n",
      "Checking received and received\n",
      "received\n",
      "Number of these words in the text:\n",
      " 3\n",
      "\n",
      "Checking god and god\n",
      "Checking god and god\n",
      "Checking god and god\n",
      "Checking god and god\n",
      "Checking god and god\n",
      "Checking god and god\n",
      "Checking god and god\n",
      "Checking god and god\n",
      "Checking god and god\n",
      "Checking god and god\n",
      "Checking god and god\n",
      "Checking god and god\n",
      "god\n",
      "Number of these words in the text:\n",
      " 12\n",
      "\n",
      "\n",
      "Number of these words in the text:\n",
      " 0\n",
      "\n",
      "Checking wilderness and wilderness\n",
      "wilderness\n",
      "Number of these words in the text:\n",
      " 1\n",
      "\n",
      "Checking blood and blood\n",
      "blood\n",
      "Number of these words in the text:\n",
      " 1\n",
      "\n",
      "Checking shineth and shineth\n",
      "shineth\n",
      "Number of these words in the text:\n",
      " 1\n",
      "\n",
      "Checking jona and jona\n",
      "Checking jona and israelite\n",
      "israelite, jona\n",
      "Number of these words in the text:\n",
      " 2\n",
      "\n",
      "Checking men and men\n",
      "Checking men and men\n",
      "men\n",
      "Number of these words in the text:\n",
      " 2\n",
      "\n",
      "Checking fig and fig\n",
      "Checking fig and fig\n",
      "fig\n",
      "Number of these words in the text:\n",
      " 2\n",
      "\n",
      "Checking open and open\n",
      "open\n",
      "Number of these words in the text:\n",
      " 1\n",
      "\n",
      "Checking seeth and seeth\n",
      "seeth\n",
      "Number of these words in the text:\n",
      " 1\n",
      "\n",
      "\n",
      "Number of these words in the text:\n",
      " 0\n",
      "\n",
      "Word group quantity: \n",
      " 99\n"
     ]
    }
   ],
   "source": [
    "# Loading the medium-sized spacy English model\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "# Creating a SpaCy document. Since the argument has to be a string, \n",
    "# we have to make a string from the prepared word set first:\n",
    "doc_spacy = nlp(\" \".join([aword for aword in word_list]))  \n",
    "\n",
    "word_groups = list()\n",
    "current_word_set = set()\n",
    "frequency_dict = dict()\n",
    "words_checked = set()\n",
    "i = 0 # word group counter\n",
    "for aword in word_set:\n",
    "    if aword not in words_checked:\n",
    "        aword_nlp = nlp(aword) # \n",
    "        j = 0 # words in a group counter\n",
    "        for w in doc_spacy:            \n",
    "            if w.has_vector and aword_nlp.similarity(w) > 0.9:  # checking for similarity; 0.x is similarity threshold\n",
    "                    print(f'Checking {aword_nlp.text} and {w.text}')\n",
    "                    current_word_set.add(w.text) \n",
    "                    words_checked.add(w.text)           \n",
    "                    j += 1\n",
    "        word_groups.append(current_word_set) # appending the found set of similar words to global list\n",
    "        frequency_dict[i] = j\n",
    "        print(', '.join([w for w in current_word_set]))\n",
    "        print(f'Number of these words in the text:\\n {j}\\n')\n",
    "        current_word_set = set() # init the current set again\n",
    "        i += 1 # increase counter\n",
    "    \n",
    "# print(f\"Word set (to be empty): \\n {word_set}\")\n",
    "# print(f\"Word groups: \\n {word_groups}\")\n",
    "# print(f'{frequency_dict}')\n",
    "print(f\"Word group quantity: \\n {len(word_groups)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Сортируем полученный словарь по значению ключа (дающего частотность соответствующей группы схожих слов)\n",
    "12. Отбираем 10 наиболее часто встречающихся групп слов в полученном словаре.\n",
    "13. Если в полученном словаре есть еще группы с той же частотностью, что и у десятой группы, также включаем их в выводимый результат. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequent word groups:\n",
      "1. The word group\n",
      "\"{'verily', 'saith', 'forth', 'prophets', 'holy', 'cometh', 'disciples', 'behold', 'fulness', 'spake', 'prophet'}\"\n",
      " - has the frequency 11\n",
      "2. The word group\n",
      "\"{'gave', 'came', 'asked', 'cried', 'turned', 'stood', 'saw', 'knew', 'heard', 'said', 'walked'}\"\n",
      " - has the frequency 11\n",
      "3. The word group\n",
      "\"{'good', 'called', 'thing', 'come', 'straight', 'things', 'way', 'know', 'time'}\"\n",
      " - has the frequency 9\n",
      "4. The word group\n",
      "\"{'joseph', 'simon', 'john', 'andrew', 'peter'}\"\n",
      " - has the frequency 5\n",
      "5. The word group\n",
      "\"{'king', 'ghost', 'sin', 'darkness', 'lord'}\"\n",
      " - has the frequency 5\n",
      "6. The word group\n",
      "\"{'christ', 'pharisees', 'jesus', 'priests'}\"\n",
      " - has the frequency 4\n",
      "7. The word group\n",
      "\"{'follow', 'speak', 'sent', 'seek'}\"\n",
      " - has the frequency 4\n",
      "8. The word group\n",
      "\"{'ask', 'write', 'answer', 'answered'}\"\n",
      " - has the frequency 4\n",
      "9. The word group\n",
      "\"{'world', 'life', 'spirit'}\"\n",
      " - has the frequency 3\n",
      "10. The word group\n",
      "\"{'man', 'sons', 'son'}\"\n",
      " - has the frequency 3\n",
      "11. The word group\n",
      "\"{'dwelt', 'taketh', 'begotten'}\"\n",
      " - has the frequency 3\n",
      "12. The word group\n",
      "\"{'heaven', 'glory', 'grace'}\"\n",
      " - has the frequency 3\n"
     ]
    }
   ],
   "source": [
    "frequency_dict_sorted = sorted(frequency_dict.items(), key = lambda item: item[1])\n",
    "print('The most frequent word groups:')\n",
    "\n",
    "# extracting the most frequent words\n",
    "if len(word_groups) > 10:\n",
    "    max_num = 10\n",
    "else:\n",
    "    max_num = len(word_groups)\n",
    "\n",
    "for i in range(max_num):\n",
    "    group_num = frequency_dict_sorted[-i-1][0]\n",
    "    word_group = word_groups[group_num]\n",
    "    frequency = frequency_dict_sorted[-i-1][1]\n",
    "    print(f'{i+1}. The word group\\n\"{word_group}\"\\n - has the frequency {frequency}')\n",
    "\n",
    "# extracting also the 11th, 12th etc, if the frequency is the same as for the 10th one:\n",
    "j = 1\n",
    "while (i+j < len(word_groups)-2) and (frequency_dict_sorted[-i-j-1][1] == frequency_dict_sorted[-i-1][1]):\n",
    "    group_num = frequency_dict_sorted[-i - j - 1][0]\n",
    "    word_group = word_groups[group_num]\n",
    "    frequency = frequency_dict_sorted[-i - j -1][1]\n",
    "    print(f'{i + j + 1}. The word group\\n\"{word_group}\"\\n - has the frequency {frequency}')\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, нами был проделан анализ англоязычного текста в отношении количества слов в предложениях, а также количества уникальных слов в тексте с объединением слов по критерию схожести.\n",
    "\n",
    "Выводы:\n",
    "1. В анализируемом классическом англоязычном тексте 17 в. тексте на ~1000 слов имеется 60 предложений, в среднем по 16.7 слов в каждом.\n",
    "3. В данном тексте после удаления стоп-слов и объединения оставшихся по принципу схожести оказалось 99 групп слов. Таким образом, отдельных групп оказалось в десять раз меньше,  чем общее число всех слов.\n",
    "4. Десять отобранных уникальных слов с максимальной частотностью дают хорошее представление о тематике текста."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
