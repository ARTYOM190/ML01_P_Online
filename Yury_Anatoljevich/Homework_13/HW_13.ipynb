{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ДЗ по итогам лекции 16.\n",
    "\n",
    "\"Использовать полученные знания в части обучения моделей для обучения и подбора параметров в задачах из предыдущих ДЗ на выбор (мфо, задача с тем возьмёт ли человек кредит или нет)\n",
    "В частности использовать:\n",
    "\n",
    "GaussianNB\n",
    "\n",
    "LogisticRegression \n",
    "\n",
    "Linear + PolynomialFeatures\n",
    "\n",
    "RandomForestClassifier \n",
    "\n",
    "При обучении использовать make_pipeline\n",
    "\n",
    "GridSearchCV для поиска параметров \n",
    "\n",
    "Посчитать метрики (f1 + точность + AUC). \"\n",
    "\n",
    "\n",
    "Анализ задания и план работы. В части подготовки данных повторяем шаги из предыдущих работ.\n",
    "Следует загрузить файл данных credit_train.csv, представленный в формате csv, в датафрейм модуля pandas.\n",
    "*) Далее следует провести поиск пропусков и удалить строки с пропусками.\n",
    "*) Кроме того, предварительный анализ файла данных показывает, что колонка living region содержит много дублей типа \"московская обл\" и \"обл московская\" или \"чеченская республика\" и \"чеченская респ\". Придется поработать с данными этой колонки, чтобы привести систему обозначений регионов к однозначной. Поскольку регионов слишком много, что затруднит анализ корреляции данных, то мы приведем всю систему к федеральным округам и двум столицам - Москва и Санкт-Петербург.\n",
    "*) Далее для оценки выбросов числовых данных следует провести оценку матожидания и дисперсии каждого столбца данных, представленного в численном виде. Все значения, отстоящие более чем на 3 выборочных стандартных отклонения, удаляем из массива данных (точнее, удаляем из выборки все объекты, для которых хотя бы в одном столбце имеются выбросы).\n",
    "*) С помощью функций подключенной библиотек оценим нормальность распределений данных\n",
    "*) Числовые колонки данных масштабируем, поделив на максимальный элемент каждой колонки\n",
    "\n",
    "\n",
    "Далее, после подготовки данных, выполняем анализ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем данные.\n",
    "Выводим для ознакомления заголовочную строку и первые пять строк. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in the initial table: 170746\n",
      "Initial column number: 15\n",
      "   client_id gender   age marital_status job_position  credit_sum  \\\n",
      "0          1      M   NaN            NaN          UMN    59998.00   \n",
      "1          2      F   NaN            MAR          UMN    10889.00   \n",
      "2          3      M  32.0            MAR          SPC    10728.00   \n",
      "3          4      F  27.0            NaN          SPC    12009.09   \n",
      "4          5      M  45.0            NaN          SPC         NaN   \n",
      "\n",
      "   credit_month tariff_id  score_shk education        living_region  \\\n",
      "0            10       1.6        NaN       GRD   КРАСНОДАРСКИЙ КРАЙ   \n",
      "1             6       1.1        NaN       NaN               МОСКВА   \n",
      "2            12       1.1        NaN       NaN      ОБЛ САРАТОВСКАЯ   \n",
      "3            12       1.1        NaN       NaN    ОБЛ ВОЛГОГРАДСКАЯ   \n",
      "4            10       1.1   0.421385       SCH  ЧЕЛЯБИНСКАЯ ОБЛАСТЬ   \n",
      "\n",
      "   monthly_income  credit_count  overdue_credit_count  open_account_flg  \n",
      "0         30000.0           1.0                   1.0                 0  \n",
      "1             NaN           2.0                   0.0                 0  \n",
      "2             NaN           5.0                   0.0                 0  \n",
      "3             NaN           2.0                   0.0                 0  \n",
      "4             NaN           1.0                   0.0                 0  \n"
     ]
    }
   ],
   "source": [
    "# %reset   # resetting variables\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "data_table = pd.read_csv('credit_train.csv', sep = ';', decimal = ',', encoding = 'windows-1251')\n",
    "print(f'Rows in the initial table: {len(data_table)}') \n",
    "print(f'Initial column number: {data_table.shape[1]}')\n",
    "print(data_table.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим сразу много NaN. \n",
    "Это процедура загрузки так заменила пропуски.\n",
    "Такие строки подлежат устранению.\n",
    "Удаляем строки c NaN (то есть с отсутствовавшими изначально значениями, которые при загрузке с помощью функции read_csv превратились в NaN) c помощью dropna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    client_id gender   age marital_status job_position  credit_sum  \\\n",
      "7           8      F  26.0            UNM          SPC     47878.0   \n",
      "9          10      F  32.0            UNM          SPC     26268.0   \n",
      "10         11      M  26.0            MAR          SPC     16793.0   \n",
      "12         13      M  37.0            MAR          SPC     42289.0   \n",
      "13         14      M  43.0            MAR          INP     57567.0   \n",
      "\n",
      "    credit_month tariff_id  score_shk education        living_region  \\\n",
      "7             10       1.1   0.512525       GRD       МОСКОВСКАЯ ОБЛ   \n",
      "9             10       1.1   0.465026       GRD  КРАЙ СТАВРОПОЛЬСКИЙ   \n",
      "10            14       1.0   0.445430       SCH      САНКТ-ПЕТЕРБУРГ   \n",
      "12            10       1.6   0.691609       SCH    ОБЛ АРХАНГЕЛЬСКАЯ   \n",
      "13            10       1.1   0.341164       GRD  ХАНТЫ-МАНСИЙСКИЙ АО   \n",
      "\n",
      "    monthly_income  credit_count  overdue_credit_count  open_account_flg  \n",
      "7          60000.0           3.0                   0.0                 0  \n",
      "9          39500.0           7.0                   0.0                 0  \n",
      "10         36000.0           2.0                   0.0                 0  \n",
      "12         70000.0           1.0                   0.0                 0  \n",
      "13         60000.0           7.0                   0.0                 0  \n",
      "Размер таблицы (161331, 15)\n"
     ]
    }
   ],
   "source": [
    "data_table.dropna(inplace=True) # inplace means we change data_table itself, not create new modified one\n",
    "print(data_table.head())\n",
    "print(f'Размер таблицы {data_table.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь следует обработать колонку living region. \n",
    "Поскольку регионов слишком много, работа сразу со всеми даст громоздкие результаты, анализ которых затруднен.\n",
    "Поэтому мы объединим все регионы по федеральным округам плюс отдельно укажем Москву и Петербург. \n",
    "Получим ровно десять living regions:\n",
    "1. Центральный ФО\n",
    "2. Северо-Западный ФО\n",
    "3. Южный ФО\n",
    "4. Северо-Кавказский ФО\n",
    "5. Приволжский  ФО\n",
    "6. Уральский ФО\n",
    "7. Сибирский ФО\n",
    "8. Дальневосточный ФО\n",
    "9. Москва\n",
    "10. Санкт-Петербург\n",
    "\n",
    "С таким количеством регионов уже можно работать.\n",
    "Попутно отметим, что в таблице два раза встречается регион \"Россия\". Его убираем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now the table shape is: (161329, 15)\n",
      "    client_id gender   age marital_status job_position  credit_sum  \\\n",
      "7           8      F  26.0            UNM          SPC     47878.0   \n",
      "9          10      F  32.0            UNM          SPC     26268.0   \n",
      "10         11      M  26.0            MAR          SPC     16793.0   \n",
      "12         13      M  37.0            MAR          SPC     42289.0   \n",
      "13         14      M  43.0            MAR          INP     57567.0   \n",
      "\n",
      "    credit_month tariff_id  score_shk education         living_region  \\\n",
      "7             10       1.1   0.512525       GRD        Центральный ФО   \n",
      "9             10       1.1   0.465026       GRD  Северо-Кавказский ФО   \n",
      "10            14       1.0   0.445430       SCH       Санкт-Петербург   \n",
      "12            10       1.6   0.691609       SCH    Северо-Западный ФО   \n",
      "13            10       1.1   0.341164       GRD          Уральский ФО   \n",
      "\n",
      "    monthly_income  credit_count  overdue_credit_count  open_account_flg  \n",
      "7          60000.0           3.0                   0.0                 0  \n",
      "9          39500.0           7.0                   0.0                 0  \n",
      "10         36000.0           2.0                   0.0                 0  \n",
      "12         70000.0           1.0                   0.0                 0  \n",
      "13         60000.0           7.0                   0.0                 0  \n"
     ]
    }
   ],
   "source": [
    "# looking for the region 'Россия' and removing it:\n",
    "indices = data_table.index[data_table['living_region'] == 'РОССИЯ']\n",
    "for ind in indices:\n",
    "    data_table = data_table.drop(index = ind)\n",
    "\n",
    "# function returning the string replace_to if a data_cell contains a string from string_set\n",
    "def replace_cell_value(data_cell, string_set, replace_to):\n",
    "    for str in string_set:\n",
    "        if str in data_cell:\n",
    "            return replace_to            \n",
    "    return data_cell # if no string in string_set is present in data_cell\n",
    "\n",
    "# the regions of every federal district, keywords:\n",
    "central_fo = ['БЕЛГОРОД', 'БРЯНСК', 'ВЛАДИМИР', 'ВОРОНЕЖ', 'ГУСЬ', 'ИВАНОВ', 'КАЛУГ', 'КАЛУЖ', 'КОСТРОМ', 'КУРСК', 'ЛИПЕЦК', 'МОСКОВСК', 'МЫТИЩ', 'ОРЕЛ', 'ОРЁЛ', 'ОРЛОВСК', 'РЯЗАН', 'СМОЛЕНСК', 'ТАМБОВ', 'ТВЕР', 'ТУЛА', 'ТУЛЬСК', 'ЯРОСЛАВ'] \n",
    "north_west_fo = ['КАРЕЛ','КОМИ','АРХАНГ','ВОЛОГ','КАЛИНИНГР','ЛЕНИНГР','МУРМАН','НОВГОРОД','ПСКОВ','НЕНЕЦК']\n",
    "south_fo = ['АДЫГ','КАЛМЫК','КРЫМ','КРАСНОДАР','АСТРАХАН','ВОЛГОГРАД','РОСТОВ','СЕВАСТ']\n",
    "caucas_fo =['ДАГЕСТ','ИНГУШ','КАБАРДИН','БАЛКАР','КАРАЧАЕВ','ЧЕРКЕС','ОСЕТИ','АЛАНИ','ЧЕЧЕН','ЧЕЧНЯ','СТАВРОПОЛ']\n",
    "volga_fo = ['ПРИВОЛЖСК','БАШКИР','БАШКОР', 'ГОРЬКИЙ', 'ГОРЬКОВСК', 'МАРИЙ','МОРДОВ','ТАТАР','УДМУРТ','ЧУВАШ','ПЕРМ','КИРОВ','НИЖЕГОРОД','НИЖНИЙ','ОРЕНБУРГ','ПЕНЗ','САМАР','САРАТОВ','УЛЬЯН','СИМБИРС']\n",
    "urals_fo =['ЕКАТЕРИНБ','СВЕРДЛОВ','КУРГАН','ТЮМЕН','ЧЕЛЯБ','ТАГИЛ','ХАНТЫ','МАНСИ','ЯМАЛ','НЕНЕЦ', '74']\n",
    "siberia_fo = ['АЛТАЙ','ТЫВА','ТУВА','ТУВИН','ХАКАС','КРАСНОЯРСК','ИРКУТСК','КЕМЕРОВ','КУЗБАСС','НОВОСИБ','ОМСК', 'ЭВЕНК']\n",
    "far_east_fo = ['ВЛАДИВОСТ','ХАБАРОВ','БУРЯТ','САХА','ЯКУТ','БАЙКАЛ','КАМЧАТ','ПРИМОРСК','АМУР','МАГАДАН','САХАЛИН','ЕВРЕЙ','ЧИТА', 'ЧИТИН', 'ЧУКОТ']\n",
    "moskau = ['МОСКВ']\n",
    "piter = ['ПЕТЕРБ', '98']\n",
    "regions = [central_fo, north_west_fo, south_fo, caucas_fo, volga_fo, urals_fo, siberia_fo, far_east_fo, moskau, piter]\n",
    "\n",
    "# regions to be put into dataset:\n",
    "federal_districts = ['Центральный ФО', 'Северо-Западный ФО', 'Южный ФО', 'Северо-Кавказский ФО', 'Приволжский  ФО', 'Уральский ФО', 'Сибирский ФО', 'Дальневосточный ФО', 'Москва', 'Санкт-Петербург']\n",
    "\n",
    "# Replacing the cells in living_region with federal districts\n",
    "i = 0\n",
    "for region in regions:\n",
    "    data_table['living_region'] = data_table['living_region'].map(lambda x: replace_cell_value(x, region, federal_districts[i]))\n",
    "    i += 1\n",
    "\n",
    "# saving result for debugging purposes\n",
    "# data_table.to_csv('tmp.csv', index = False, sep=';', decimal = ',', encoding = 'windows-1251') \n",
    "print(f'Now the table shape is: {data_table.shape}')\n",
    "print(data_table.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все колонки делим на две категории - числовые и нечисловые. \n",
    "Числовые будут далее исследоваться на выбросы и затем проверяться на нормальность, затем нормироваться.\n",
    "Нечисловые колонки кодируем энкодером OneHotEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New length of table: 161329\n",
      "New column number: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Column titles of categorical features\n",
    "categorical_features_onehot = ['gender', 'marital_status', 'education', 'living_region'] # for encoding by onehot encoder\n",
    "# Even though tariff_id consists from zeros and units, but is in fact non-numerical, since it is the tariff category\n",
    "categorical_features_label = ['tariff_id', 'job_position']  # for encoding by label encoder\n",
    "# Column titles of numerical features\n",
    "numerical_features = ['age', 'credit_sum', 'credit_month', 'score_shk', 'monthly_income', 'credit_count', 'overdue_credit_count', 'open_account_flg']\n",
    "\n",
    "# creating dataframe for encoded values. First including only numeric data there\n",
    "data_table_encoded = data_table[numerical_features] # dataframe for encoded data set\n",
    "data_table_encoded.reset_index(drop=True, inplace = True) # changing series indices to sequential incrementing values\n",
    "# print(data_table_encoded.head()) \n",
    "\n",
    "# transform the categorical data using OneHotEncoder\n",
    "encoder = OneHotEncoder() # init encoder\n",
    "for feature in categorical_features_onehot:\n",
    "    # print(feature)\n",
    "    tmp_data = encoder.fit_transform(data_table[[feature]]) # coded data is sparse matrix\n",
    "    tmp_data = tmp_data.todense() # to usual matrix \n",
    "    # print(tmp_data)\n",
    "    # extract the feature names for the encoded columns\n",
    "    tmp_titles = encoder.get_feature_names_out([feature])\n",
    "    # print(tmp_titles)\n",
    "    tmp_df = pd.DataFrame(tmp_data, columns = tmp_titles)    \n",
    "    data_table_encoded = pd.concat([data_table_encoded, tmp_df], axis = 1, ignore_index = False, sort = False) # merging into the encoded dataframe     \n",
    "    # print(f'Current table size: {data_table_encoded.shape}')\n",
    "\n",
    "# transform other categorical data using LabelEncoder\n",
    "encoder = LabelEncoder() # init encoder\n",
    "for feature in categorical_features_label:\n",
    "    # print(feature)    \n",
    "    data_table_encoded[feature] = encoder.fit_transform(data_table[[feature]])    \n",
    "\n",
    "print(f'New length of table: {len(data_table_encoded)}')\n",
    "print(f'New column number: {data_table_encoded.shape[1]}')\n",
    "\n",
    "# for debugging only:\n",
    "# print(data_table_encoded.head())\n",
    "# data_table_encoded.to_csv('tmp1.csv', sep = ';', decimal = '.', encoding = 'windows-1251')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассчитываем выбросы и отсеиваем строки с выбросами (где значения отстоят больше чем на 3 стандартных отклонения от среднего).\n",
    "Отметим, что из колонок типа 'overdue_credit_count', 'open_account_flg' отсеивать выбросы не следует. Дело в том, что, например, в колонке 'overdue_credit_count' большинство значений нулевые, и очень редко, например, число просроченных кредитов равно 1, 2 или 3. Тогда среднее значение будет околонулевым, дисперсия из-за подавляющего превосходства в числе нулевых значений тоже будет мала, и поэтому отсеивание выбросов по принципу, применимому для гауссова распределения, то есть отстоящих более чем на три сигмы от среднего значения, просто уберет из колонки все ненулевые значения и тем самым обнулит ценность самой колонки.\n",
    "Поэтому для отсеивания выбросов отберем только колонки, где имеется множество различных значений, а именно: age, credit_sum, score_shk, monthly_income."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: age, mean: 37.0, std: 10.4\n",
      "Current table size: 5151456\n",
      "Feature: credit_sum, mean: 25942.8, std: 16194.6\n",
      "Current table size: 5093632\n",
      "Feature: score_shk, mean: 0.5, std: 0.1\n",
      "Current table size: 5089888\n",
      "Feature: monthly_income, mean: 40077.5, std: 24666.0\n",
      "Current table size: 5021984\n",
      "Now the table shape is: (156937, 32)\n"
     ]
    }
   ],
   "source": [
    "# calculating the means and standard deviations over some numerical columns\n",
    "where_remove_outliers = ['age', 'credit_sum', 'score_shk', 'monthly_income']\n",
    "# removing outliers (i.e. leaving only rows withot outliers)\n",
    "# i = 1\n",
    "for feature in where_remove_outliers:\n",
    "    mean = data_table_encoded[feature].mean()\n",
    "    std = data_table_encoded[feature].std()\n",
    "    print(f'Feature: {feature}, mean: {mean:.1f}, std: {std:.1f}')\n",
    "    # z_scores i.e. distance from the data value to mean, in std values\n",
    "    z_scores = (data_table_encoded[feature] - mean) / std # absolute value of z score\n",
    "    z_scores = z_scores.abs()\n",
    "    # print(z_scores)\n",
    "    # z_scores.to_csv('tmp_z'+ str(i) + '.csv', sep = ';', decimal = '.', encoding = 'windows-1251')\n",
    "    # i += 1\n",
    "    # if z_scores are > 3 the data is considered to be an outlier:\n",
    "    data_table_encoded = data_table_encoded[z_scores <= 3] # leaving only items closer to the mean value (not farther than 3*sigma)\n",
    "    # another variant:\n",
    "    # mask = z_scores.abs().lt(3) # mask to remove all rows with z values >=3\n",
    "    # data_table_encoded = data_table_encoded[mask] # leaving only items closer to the mean value (not farther than 3*sigma)\n",
    "    print(f'Current table size: {data_table_encoded.size}')\n",
    " \n",
    "data_table_encoded.reset_index(drop = True, inplace = True) # changing final series indices to incrementing values\n",
    "data_table_encoded.to_csv('tmp_encoded.csv', sep = ';', decimal = '.', encoding = 'windows-1251')   \n",
    "print(f'Now the table shape is: {data_table_encoded.shape}')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее следует масштабировать данные - то есть поделить числовые колонки на их максимумы.\n",
    "В финале сохранить полученные предобработанные данные для дальнейшего использования в какой-либо модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156937, 32)\n"
     ]
    }
   ],
   "source": [
    "for feature in numerical_features:\n",
    "    data_table_encoded[feature] = data_table_encoded[feature] / data_table_encoded[feature].max()\n",
    "\n",
    "# data_table_encoded.to_csv('credit_train_preprocessed.csv', sep = ';', decimal = '.', encoding = 'windows-1251')  \n",
    "print(data_table_encoded.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Учтем, что решаемая нами задача - определение по признакам кредитополучателей, получит ли кредит кредитополучатель, является задачей бинарной классификации. То есть мы должны по набору признаков кредитополучателя предсказать значение в колонке open_account_flg, показывающей, получил ли кредитополучатель кредит.\n",
    "В задачах бинарной классификации бывает целесообразно сбалансировать обучающую выборку, то есть выравнять количество элементов обучающего набора, относящихся к каждому из двух классов кредитополучателей (получивших кредит, т.е. для которых open_account_flg == 1, и не получивших кредит, т.е. для которых open_account_flg == 0). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "open_account_flg\n",
      "0.0    131084\n",
      "1.0     25853\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "tmp = data_table_encoded['open_account_flg'].value_counts() # extracting the number of each value in the column 'open_account_flg'\n",
    "print(tmp)\n",
    "# extracting all samples with 'open_account_flg'== 1:\n",
    "samples_1 = data_table_encoded[data_table_encoded['open_account_flg'] == 1]\n",
    "# extracting all samples with 'open_account_flg'== 0:\n",
    "samples_0 = data_table_encoded[data_table_encoded['open_account_flg'] == 0]\n",
    "# sampling a sub-sample from samples_0 with the size equal to the one of the  \n",
    "samples_00 = samples_0.sample(n = tmp[1], random_state = 42) # 42 is the seed for random number generator\n",
    "\n",
    "data_table_preprocessed = pd.concat([samples_1, samples_00]) # new data table with equal number of open_account_flg = 0 and = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверяем размеры нового датасета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51706, 32)\n",
      "(25853, 32)\n",
      "(25853, 32)\n"
     ]
    }
   ],
   "source": [
    "print(data_table_preprocessed.shape)\n",
    "print(data_table_preprocessed[data_table_preprocessed['open_account_flg'] == 0].shape)\n",
    "print(data_table_preprocessed[data_table_preprocessed['open_account_flg'] == 1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужно разделить датасет на две выборки - обучающую и тестовую.\n",
    "Но вначале нужно разделить таблицу данных на две: на набор колонок X, значения которых будут служить аргументом, подаваемым на вход модели, и колонку меток Y, на получение которой и натренировывается модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = data_table_preprocessed.drop(columns=['open_account_flg'])\n",
    "Y = data_table_preprocessed['open_account_flg']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For debugging:\n",
    "# X_train.to_csv('X_train.csv', sep = ';', decimal = '.', encoding = 'windows-1251')   \n",
    "Y_train.to_csv('Y_train.csv', sep = ';', decimal = '.', encoding = 'windows-1251') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем обучение классификатора GaussianNB (Gaussian Naive Bayesian). При этом в данном случае GridSearchCV для поиска параметров не используется, потому что для GaussianNB никакие параметры не подбираются. Как требуется по заданию, используем make_pipeline.\n",
    "Для любого классификатора в sklearn используется похожая последовательность действий:\n",
    "Создается экземпляр классификатора.\n",
    "Проводится обучение методом fit.\n",
    "Предсказываются значения меток с помощью обученного классификатора вызовом метода predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# creating pipeline\n",
    "pipe = make_pipeline(StandardScaler(), GaussianNB())\n",
    "\n",
    "# training pipeline\n",
    "pipe.fit(X_train, Y_train)\n",
    "\n",
    "# predicting class labels\n",
    "Y_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes metrics:\n",
      "F1 metrics: 0.46\n",
      "Accuracy metrics: 0.56\n",
      "Area under curve metrics: 0.56\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# calculating metrics for Gaussian Naive Bayes:\n",
    "F1 = f1_score(Y_test, Y_pred)\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "AUC = roc_auc_score(Y_test, Y_pred)\n",
    "\n",
    "print('Gaussian Naive Bayes metrics:')\n",
    "print(f'F1 metrics: {F1:.2f}')\n",
    "print(f'Accuracy metrics: {accuracy:.2f}')\n",
    "print(f'Area under curve metrics: {AUC:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем классификатор LogisticRegression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression metrics:\n",
      "F1 metrics: 0.59\n",
      "Accuracy metrics: 0.59\n",
      "Area under curve metrics: 0.59\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# creating pipeline\n",
    "pipe = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "\n",
    "# training pipeline\n",
    "pipe.fit(X_train, Y_train)\n",
    "\n",
    "# predicting class labels\n",
    "Y_pred = pipe.predict(X_test)\n",
    "\n",
    "# calculating metrics for LogisticRegression:\n",
    "F1 = f1_score(Y_test, Y_pred)\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "AUC = roc_auc_score(Y_test, Y_pred)\n",
    "\n",
    "print('Logistic Regression metrics:')\n",
    "print(f'F1 metrics: {F1:.2f}')\n",
    "print(f'Accuracy metrics: {accuracy:.2f}')\n",
    "print(f'Area under curve metrics: {AUC:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем классификатор\n",
    "Linear Regression + PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create a pipeline with PolynomialFeatures and LinearRegression\n",
    "pipe = make_pipeline(\n",
    "    PolynomialFeatures(),\n",
    "    LinearRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the parameter grid for GridSearchCV\n",
    "param_grid = {'polynomialfeatures__degree': [1, 2, 3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv = 5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:982: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 971, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 279, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 231, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 112, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:982: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 971, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 279, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 231, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 112, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:982: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 971, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 279, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 231, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 112, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:982: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 971, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 279, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 231, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 112, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:982: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 971, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 279, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 231, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 112, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:982: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 971, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 279, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 231, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 112, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:982: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 971, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 279, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 231, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 112, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(X_train, Y_train)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1018\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1013\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1014\u001b[0m     )\n\u001b[0;32m   1016\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1018\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1572\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1570\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1572\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:964\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    957\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    958\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    960\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    961\u001b[0m         )\n\u001b[0;32m    962\u001b[0m     )\n\u001b[1;32m--> 964\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    965\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    966\u001b[0m         clone(base_estimator),\n\u001b[0;32m    967\u001b[0m         X,\n\u001b[0;32m    968\u001b[0m         y,\n\u001b[0;32m    969\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    970\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    971\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    972\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    973\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    974\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    975\u001b[0m     )\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[0;32m    978\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[0;32m    979\u001b[0m     )\n\u001b[0;32m    980\u001b[0m )\n\u001b[0;32m    982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    983\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    984\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    987\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:888\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    886\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    887\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 888\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    890\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    891\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    892\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:473\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    472\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m routed_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m--> 473\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlast_step_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    475\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1468\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m global_skip_validation \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m partial_fit_and_fitted:\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m-> 1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[0;32m   1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\contextlib.py:144\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\_config.py:371\u001b[0m, in \u001b[0;36mconfig_context\u001b[1;34m(assume_finite, working_memory, print_changed_only, display, pairwise_dist_chunk_size, enable_cython_pairwise_dist, array_api_dispatch, transform_output, enable_metadata_routing, skip_parameter_validation)\u001b[0m\n\u001b[0;32m    357\u001b[0m set_config(\n\u001b[0;32m    358\u001b[0m     assume_finite\u001b[38;5;241m=\u001b[39massume_finite,\n\u001b[0;32m    359\u001b[0m     working_memory\u001b[38;5;241m=\u001b[39mworking_memory,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    367\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39mskip_parameter_validation,\n\u001b[0;32m    368\u001b[0m )\n\u001b[0;32m    370\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 371\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    373\u001b[0m     set_config(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mold_config)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "grid_search.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:982: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 971, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 279, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 231, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 112, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:982: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 971, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 279, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 231, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 112, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:982: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 971, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 279, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 231, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 112, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:982: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 971, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 279, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 231, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 112, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:982: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 971, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 279, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 231, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 112, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:982: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 971, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 279, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 231, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 112, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:982: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 971, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 279, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 231, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 112, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:982: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 971, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 279, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 231, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 112, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:982: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 971, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 279, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 231, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 112, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:982: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 971, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 279, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 231, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 112, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[1;32mIn[41], line 18\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(X_train, Y_train)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Print best parameters and best score\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1018\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1016\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1018\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1572\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1572\u001b[0m evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:964\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    957\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    958\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    960\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    961\u001b[0m         )\n\u001b[0;32m    962\u001b[0m     )\n\u001b[1;32m--> 964\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    965\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    966\u001b[0m         clone(base_estimator),\n\u001b[0;32m    967\u001b[0m         X,\n\u001b[0;32m    968\u001b[0m         y,\n\u001b[0;32m    969\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    970\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    971\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    972\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    973\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    974\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    975\u001b[0m     )\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[0;32m    978\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[0;32m    979\u001b[0m     )\n\u001b[0;32m    980\u001b[0m )\n\u001b[0;32m    982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:888\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 888\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    890\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    891\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:473\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    472\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m routed_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m--> 473\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlast_step_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    475\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:687\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 687\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_, _, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrank_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msingular_ \u001b[38;5;241m=\u001b[39m linalg\u001b[38;5;241m.\u001b[39mlstsq(X, y)\n\u001b[0;32m    688\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\scipy\\linalg\\_basic.py:1270\u001b[0m, in \u001b[0;36mlstsq\u001b[1;34m(a, b, cond, overwrite_a, overwrite_b, check_finite, lapack_driver)\u001b[0m\n\u001b[0;32m   1269\u001b[0m     lwork, iwork \u001b[38;5;241m=\u001b[39m _compute_lwork(lapack_lwork, m, n, nrhs, cond)\n\u001b[1;32m-> 1270\u001b[0m     x, s, rank, info \u001b[38;5;241m=\u001b[39m lapack_func(a1, b1, lwork,\n\u001b[0;32m   1271\u001b[0m                                    iwork, cond, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1272\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# complex data\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:2115\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2112\u001b[0m     msg \u001b[38;5;241m=\u001b[39m traceback\u001b[38;5;241m.\u001b[39mformat_exception_only(etype, value)\n\u001b[0;32m   2113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(msg)\n\u001b[1;32m-> 2115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshowtraceback\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_tuple\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, tb_offset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2116\u001b[0m                   exception_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, running_compiled_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   2117\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Display the exception that just occurred.\u001b[39;00m\n\u001b[0;32m   2118\u001b[0m \n\u001b[0;32m   2119\u001b[0m \u001b[38;5;124;03m    If nothing is known about the exception, this is the method which\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2125\u001b[0m \u001b[38;5;124;03m    SyntaxError exception, don't try to analyze the stack manually and\u001b[39;00m\n\u001b[0;32m   2126\u001b[0m \u001b[38;5;124;03m    simply call this method.\"\"\"\u001b[39;00m\n\u001b[0;32m   2128\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Print best parameters and best score\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: \", grid_search.best_score_)\n",
    "\n",
    "# 7. Make predictions on the training set (or split into train/test)\n",
    "Y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# 8. Evaluate the model\n",
    "print(\"Accuracy: \", accuracy_score(Y_test, Y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем классифкатор RandomForestClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводы:\n",
    "Проведена предобработка файла данных по кредитам.\n",
    "Произведена балансировка выборки - то есть отбрасывание части сэмплов с open_account_flg == 0, чтобы выравнять количество кредитополучателей, получивших и не получивших кредит.\n",
    "Произведено обучение моделей с помощью различных методов и выбраны методы, дающие наилучшие результаты согласно используемым метрикам.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
