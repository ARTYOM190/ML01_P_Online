{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68a6c278-e623-4c77-bde8-c5620c2acf62",
   "metadata": {},
   "source": [
    "# Цель"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35c8d7c-2ecc-4c9a-a248-554cc094985d",
   "metadata": {},
   "source": [
    "Реализовать с использованием потоков и процессов скачивание файлов из интернета. \n",
    "Список файлов для скачивания подготовить самостоятельно (например изображений, не менее 100 изображений или других объектов). Сравнить производительность с последовательным методом. Сравнивть производительность Thread и multiprocessing решений. Попробовать подобрать оптимальное число потоков/процессов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739b7f12-f539-430a-898f-83eb2039395c",
   "metadata": {},
   "source": [
    "Напишем программу, использующую следующие модули: \"requests\", \"os\", \"time\", \"threading\", \"multiprocessing\". Также используем предустановленную в пакет \"Anaconda\" библиотеку \"BeautifulSoup\" для реализации API скачивания изображений с Википедии."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d17571a-3bf1-4239-96b3-246010b091f5",
   "metadata": {},
   "source": [
    "Напишем API для загрузки 100 файлов из Википедии c созданием директории для их загрузки в папке с программой:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840883d1-cbed-42b3-a949-ab7988e05340",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Wed Nov 20 19:23:39 2024\n",
    "\n",
    "@author: vdmsacu\n",
    "\"\"\"\n",
    "import requests;\n",
    "import os;\n",
    "import time;\n",
    "import threading;\n",
    "from bs4 import BeautifulSoup;\n",
    "from multiprocessing import Pool;\n",
    "def image_urls(num_images=100):\n",
    "    image_urls = set();\n",
    "    while len(image_urls) < num_images:\n",
    "        response = requests.get(\"https://en.wikipedia.org/wiki/Special:Random\");\n",
    "        if response.status_code != 200:\n",
    "            continue;\n",
    "        soup = BeautifulSoup(response.text, 'html.parser');\n",
    "        for img in soup.find_all('img'):\n",
    "            img_url = 'https:' + img['src'];\n",
    "            if img_url not in image_urls:\n",
    "                image_urls.add(img_url);\n",
    "                if len(image_urls) >= num_images:\n",
    "                    break;\n",
    "    return list(image_urls);\n",
    "url_list = image_urls(100)\n",
    "def download(url):\n",
    "    try:\n",
    "        response = requests.get(url);\n",
    "        if response.status_code == 200:\n",
    "            file_name = os.path.join('images', url.split('/')[-1]);\n",
    "            with open(file_name, \"wb\") as f:\n",
    "                f.write(response.content);\n",
    "            print(f\"Скачан файл: {file_name}\");\n",
    "        else:\n",
    "            print(f\"Ошибка загрузки файла: {url}: Статус загрузки файла: {response.status_code}\");\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка скачивания файла: {url}: {e}\");\n",
    "os.makedirs('images', exist_ok=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3aee250-3613-48f6-8a22-0cc4a72957a7",
   "metadata": {},
   "source": [
    "Напишем функции для скачивания файлов в разных режимах:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89569bfd-9be9-4ab0-9c04-8a1c347c7d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential(urls):\n",
    "    for url in urls:\n",
    "        download(url);\n",
    "start_time = time.time();\n",
    "sequential(url_list);\n",
    "end_time = time.time();\n",
    "print(f\"Время последовательной загрузки файлов: {end_time - start_time} сек.\");\n",
    "def thread(urls):\n",
    "    threads = [];\n",
    "    for url in urls:\n",
    "        thread = threading.Thread(target=download, args=(url,));\n",
    "        threads.append(thread);\n",
    "        thread.start();\n",
    "    for thread in threads:\n",
    "        thread.join();\n",
    "start_time = time.time();\n",
    "thread(url_list);\n",
    "end_time = time.time();\n",
    "print(f\"Время потоковой загрузки файлов: {end_time - start_time} сек.\");\n",
    "def multiprocessing(urls):\n",
    "    with Pool(processes=os.cpu_count()) as pool:\n",
    "        pool.map(download, urls);\n",
    "start_time = time.time();\n",
    "multiprocessing(url_list);\n",
    "end_time = time.time();\n",
    "print(f\"Время загрузки файлов в мультипроцессинговом режиме: {end_time - start_time} сек.\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c83196-8447-4874-a276-c7a363b41eeb",
   "metadata": {},
   "source": [
    "# Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c82da32-5856-4c4b-8f3c-2e2f02773dce",
   "metadata": {},
   "source": [
    "Самая быстрая скорость скачивания была получена в потоковом и мультипроцессорных режимах. Скорость загрузки файлов в последовательном режиме оказалась самой медленной. Число процессоров регулируется функцией \"cpu_count()\" и подбирается индивидуально в зависимости от вычислительной мощности процессора ЭВМ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
