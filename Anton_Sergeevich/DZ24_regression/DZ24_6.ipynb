{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/ \n",
    "ДЗ - оценить возраст человека по изображению. В качестве датасета возьмите датасет только лиц. \n",
    "Предположим что сами лица вы находить и извлекать уже умеете. Можете сделать это как продолжение решения по поиску лиц из предыдущих работ.\n",
    "https://www.google.com/amp/s/www.geeksforgeeks.org/age-detection-using-deep-learning-in-opencv/amp/ пример того как это может работать.  \n",
    "В качестве фьючеэкстрактора берите любую современную нейронную сеть. Задачу можно решать как задачу регрессии или классификации.  14 14-18 \n",
    "Если есть время можете попробовать 2 способа.  Попробуйте разблокировать часть слоев после обучения и дообучить модель.\n",
    "\n",
    "\n",
    "0-14 14-17 18-21 22-\n",
    "\n",
    "\n",
    "Указание -  что бы решить задачу регресси вам нужно использовать flow_from_dataframe\n",
    "Указание - для начала вам нужно создать датафрейм в котором будет относительный путь к изображению и целевая метка, потом использовать этот датафрейм при обучении"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install dlib-19.24.99-cp312-cp312-win_amd64.whl\n",
    "#!pip install face_recognition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import face_recognition\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вырезание лиц и масштабирование их до разрешения 224*224."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обработка завершена!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cur_dir = \"./wiki_crop\"\n",
    "prefix = \"faces_60\"\n",
    "dir_full_dataset = \"./pict_more_60_pixel\"\n",
    "os.makedirs(dir_full_dataset, exist_ok=True)\n",
    "\n",
    "def process_images(input_folder,output_folder):\n",
    "    # Путь для сохранения нового датасета\n",
    "    \n",
    "    #os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for file_name in os.listdir(input_folder):\n",
    "        file_path = os.path.join(input_folder, file_name)\n",
    "        try:\n",
    "            # Загрузка изображения\n",
    "            image = face_recognition.load_image_file(file_path)\n",
    "            # Обнаружение лиц\n",
    "            face_locations = face_recognition.face_locations(image)\n",
    "            \n",
    "            for i, face_location in enumerate(face_locations):\n",
    "                top, right, bottom, left = face_location\n",
    "                face_image = image[top:bottom, left:right]\n",
    "                face_pil = Image.fromarray(face_image)\n",
    "\n",
    "                # Проверка разрешения лица\n",
    "                if face_pil.width >= 60 and face_pil.height >= 60:\n",
    "                    # Масштабирование изображения\n",
    "                    face_resized = face_pil.resize((224, 224))\n",
    "                    # Сохранение изображения\n",
    "                    output_path = os.path.join(output_folder, f\"{os.path.splitext(file_name)[0]}.jpg\")\n",
    "                    face_resized.save(output_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка обработки файла {file_name}: {e}\")\n",
    "dirs = os.listdir(cur_dir)\n",
    "for dir in dirs:\n",
    "    process_images(cur_dir+\"/\"+dir,dir_full_dataset)\n",
    "\n",
    "print(\"Обработка завершена!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка датасета в 2 массива."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка обработки файла 32339345_1994-11-18._2015.jpg: invalid literal for int() with base 10: '994-'\n",
      "Ошибка обработки файла 5139000_1963-02-006_2009.jpg: invalid literal for int() with base 10: '963-'\n",
      "Ошибка обработки файла 706798_1989-08-019_2009.jpg: invalid literal for int() with base 10: '989-'\n",
      "Датасет корректен 34349\n",
      "Некорректных файлов 3\n",
      "Корректных файлов 34349\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pict_dir = \"./pict_more_60_pixel\"\n",
    "correct_files = 0\n",
    "filepath = []\n",
    "labels = []\n",
    "dataset_lenth = 35000\n",
    "uncorrect_files = 0\n",
    "files = os.listdir(pict_dir)\n",
    "for pict in files:\n",
    "    try:        \n",
    "        year_of_card = os.path.basename(pict)[-8:-4]\n",
    "        birth  = os.path.basename(pict)[-19:-15]  \n",
    "        age =   int(year_of_card)-int(birth)\n",
    "        if (age>3 and age<105):\n",
    "            labels.append(int(year_of_card)-int(birth))\n",
    "            filepath.append(pict_dir+\"/\"+pict)        \n",
    "            #image = cv2.imread(pict_dir+\"/\"+pict)           \n",
    "            #filepath.append(image)\n",
    "            correct_files+=1\n",
    "            if correct_files>=dataset_lenth:\n",
    "                break\n",
    "            \n",
    "        \n",
    "    except Exception as e:\n",
    "        uncorrect_files+=1\n",
    "        print(f\"Ошибка обработки файла {pict}: {e}\")\n",
    "        \n",
    "if len(filepath)==len(labels):\n",
    "    print(\"Датасет корректен\",len(filepath))\n",
    "    # склеиваем данные в пандас датасет\n",
    "    Fseries=pd.Series( filepath, name = 'image' )\n",
    "    Lseries=pd.Series(labels, name = 'dx')\n",
    "    data_set = pd.concat([Fseries, Lseries], axis=1)\n",
    "else:\n",
    "    print(\"Датасет некорректен, разные длины массивов меток и данны!!!!!!!!!!!!!!! \")\n",
    "    \n",
    "print(\"Некорректных файлов\",uncorrect_files)\n",
    "print(\"Корректных файлов\",correct_files)\n",
    "#print(data_set.head)\n",
    "type(data_set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер полного датасета 34106\n",
      "test batch size:  50   test steps:  34\n",
      "Found 30695 validated image filenames.\n",
      "Found 1706 validated image filenames.\n",
      "Found 1705 validated image filenames.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Soft\\ProgramFiles\\Anaconda\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m707s\u001b[0m 455ms/step - loss: 270.5476 - mae: 11.4296 - val_loss: 160.0924 - val_mae: 9.1887\n",
      "Epoch 2/5\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m632s\u001b[0m 412ms/step - loss: 158.4678 - mae: 9.0989 - val_loss: 160.5646 - val_mae: 9.6671\n",
      "Epoch 3/5\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m574s\u001b[0m 374ms/step - loss: 151.6763 - mae: 8.9790 - val_loss: 138.3730 - val_mae: 8.5114\n",
      "Epoch 4/5\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m652s\u001b[0m 425ms/step - loss: 150.3801 - mae: 9.0031 - val_loss: 135.6179 - val_mae: 8.5509\n",
      "Epoch 5/5\n",
      "\u001b[1m1535/1535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m609s\u001b[0m 396ms/step - loss: 145.2046 - mae: 8.8303 - val_loss: 134.3306 - val_mae: 8.5079\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 142.7903 - mae: 8.3371\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable float object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 86\u001b[0m\n\u001b[0;32m     79\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit (x \u001b[38;5;241m=\u001b[39m train_gen,  epochs \u001b[38;5;241m=\u001b[39m num_epochs, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;66;03m#callbacks = my_callback,\u001b[39;00m\n\u001b[0;32m     80\u001b[0m                        validation_data \u001b[38;5;241m=\u001b[39m valid_gen, validation_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,  shuffle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,  initial_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# Оценка модели на тестовом наборе\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m#test_loss, test_mae = model.evaluate(test_df, batch_size=32)\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m test_loss, test_mae \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate( test_gen, batch_size \u001b[38;5;241m=\u001b[39m test_batch_size, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m, steps\u001b[38;5;241m=\u001b[39mtest_steps, return_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Test MAE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_mae\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable float object"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Размер картинки для подачи в модели\n",
    "height   = 224\n",
    "width    = 224\n",
    "channels = 3\n",
    "num_epochs = 5\n",
    "\n",
    "data_set = data_set[(np.abs(stats.zscore(data_set[\"dx\"])) < 3)]\n",
    "data_set[\"dx\"].describe()\n",
    "# Размер пачки для обучения\n",
    "batch_size = 20\n",
    "# Размер пачки для валидации\n",
    "test_batch_size = 50\n",
    "\n",
    "print(\"Размер полного датасета\",len(data_set))\n",
    "# Разделяем выборку на обучающую, тестовую и валидационную (случайным образом)\n",
    "\n",
    "#x_train, x_test, y_train, y_test = train_test_split(images, ages, test_size=0.2, random_state=42)\n",
    "train_df, test_df = train_test_split (data_set, train_size= .9, shuffle = True, random_state = 42)\n",
    "valid_df, test_df = train_test_split (test_df, train_size= .5, shuffle = True, random_state = 42)\n",
    "\n",
    "length    = len(test_df)\n",
    "# выводим найденное число n\n",
    "test_steps = int(length/test_batch_size)\n",
    "print ( 'test batch size: ' ,test_batch_size, '  test steps: ', test_steps)\n",
    "\n",
    "\n",
    "# Создаем генераторы для модели\n",
    "trgen = ImageDataGenerator()\n",
    "tvgen = ImageDataGenerator()\n",
    "\n",
    "# Заполнение генераторов данными:\n",
    "train_gen = trgen.flow_from_dataframe ( train_df, directory = None, x_col = \"image\", y_col = \"dx\", target_size = (height,width), class_mode = 'raw',\n",
    "                                    color_mode='rgb', shuffle=True, batch_size=batch_size)\n",
    "\n",
    "# Выборка для тестирования сети после обучения\n",
    "test_gen = tvgen.flow_from_dataframe ( test_df, directory = None, x_col= \"image\", y_col = \"dx\", target_size = (height,width), class_mode = 'raw',\n",
    "                                    color_mode='rgb', shuffle=False, batch_size=test_batch_size)\n",
    "# Выборка для тестирования сети во время обучения\n",
    "valid_gen = tvgen.flow_from_dataframe ( valid_df, directory = None, x_col=\"image\", y_col = \"dx\", target_size = (height,width), class_mode = 'raw',\n",
    "                                    color_mode='rgb', shuffle = True, batch_size = batch_size)\n",
    "\n",
    "\n",
    "\n",
    "# Загрузка предварительно обученной модели EfficientNet-B0\n",
    "base_model = EfficientNetB0(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Замораживание базовых слоёв\n",
    "base_model.trainable = False\n",
    "\n",
    "# Добавление новых слоёв\n",
    "x = base_model.output\n",
    "x = tf.keras.layers.Dropout(0.3) (x)\n",
    "x = tf.keras.layers.BatchNormalization(axis = -1, momentum = 0.99, epsilon = 0.001 )(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, kernel_regularizer = regularizers.l2(0.02), activity_regularizer = regularizers.l1(0.004),\n",
    "                bias_regularizer = regularizers.l1(0.006), activation = 'relu')(x)\n",
    "#x = Dense(128, activation=\"relu\")(x)\n",
    "output = Dense(1, activation=\"linear\")(x)  # Для регрессии\n",
    "\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Компиляция модели\n",
    "model.compile(optimizer=Adam(learning_rate=0.003), loss=\"mean_squared_error\", metrics=[\"mae\"])\n",
    "\n",
    "# Callback для остановки при переобучении\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "# Обучение модели\n",
    "#history = model.fit(    train_df,    validation_data=valid_df,    epochs=num_epochs,    batch_size=32,)\n",
    "\n",
    "history = model.fit (x = train_gen,  epochs = num_epochs, verbose = \"auto\",#callbacks = my_callback,\n",
    "                       validation_data = valid_gen, validation_steps = None,  shuffle = False,  initial_epoch = 0)\n",
    "\n",
    "\n",
    "\n",
    "test_loss, test_mae = model.evaluate( test_gen, batch_size = test_batch_size, verbose = \"auto\", steps=test_steps, return_dict = False)[1]*100\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test MAE: {test_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    9944.000000\n",
       "mean       39.966814\n",
       "std        16.083669\n",
       "min         7.000000\n",
       "25%        27.000000\n",
       "50%        35.000000\n",
       "75%        50.000000\n",
       "max        89.000000\n",
       "Name: dx, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Параметры\n",
    "image_size = (224, 224)\n",
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Загрузка данных из DataFrame\n",
    "data_set = data_set[(np.abs(stats.zscore(data_set[\"dx\"])) < 3)]\n",
    "                  \n",
    "\n",
    "file_names = data_set[\"image\"].values\n",
    "ages = data_set[\"dx\"].values\n",
    "data_set[\"dx\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 813ms/step - accuracy: 0.0000e+00 - loss: 676.1940 - mae: 20.6068 - val_accuracy: 0.0000e+00 - val_loss: 264.7451 - val_mae: 13.5300\n",
      "Epoch 2/10\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 754ms/step - accuracy: 0.0000e+00 - loss: 283.4889 - mae: 13.6765 - val_accuracy: 0.0000e+00 - val_loss: 267.2370 - val_mae: 13.9227\n",
      "Epoch 3/10\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 755ms/step - accuracy: 0.0000e+00 - loss: 278.5885 - mae: 13.5666 - val_accuracy: 0.0000e+00 - val_loss: 264.7198 - val_mae: 13.6343\n",
      "Epoch 4/10\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 750ms/step - accuracy: 0.0000e+00 - loss: 274.6518 - mae: 13.5122 - val_accuracy: 0.0000e+00 - val_loss: 264.7568 - val_mae: 13.6506\n",
      "Epoch 5/10\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 759ms/step - accuracy: 0.0000e+00 - loss: 269.3674 - mae: 13.3836 - val_accuracy: 0.0000e+00 - val_loss: 266.1627 - val_mae: 13.8396\n",
      "Epoch 6/10\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 748ms/step - accuracy: 0.0000e+00 - loss: 275.5171 - mae: 13.6458 - val_accuracy: 0.0000e+00 - val_loss: 264.8991 - val_mae: 13.4760\n",
      "Epoch 7/10\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 745ms/step - accuracy: 0.0000e+00 - loss: 275.1208 - mae: 13.5902 - val_accuracy: 0.0000e+00 - val_loss: 265.0074 - val_mae: 13.4585\n",
      "Epoch 8/10\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 741ms/step - accuracy: 0.0000e+00 - loss: 275.5965 - mae: 13.4817 - val_accuracy: 0.0000e+00 - val_loss: 265.9590 - val_mae: 13.8232\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 520ms/step - accuracy: 0.0000e+00 - loss: 241.0579 - mae: 12.9251\n",
      "Test Loss: 255.3228, Test MAE: 13.2910,, Test Accuracy: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "# Разделение на train, validate и test\n",
    "train_files, temp_files, train_ages, temp_ages = train_test_split(file_names, ages, test_size=0.4, random_state=42)\n",
    "val_files, test_files, val_ages, test_ages = train_test_split(temp_files, temp_ages, test_size=0.5, random_state=42)\n",
    "\n",
    "# Функция для загрузки изображений по названиям файлов\n",
    "def load_images(file_names):\n",
    "    images = []\n",
    "    for file_name in file_names:\n",
    "        img = load_img(file_name, target_size=image_size)\n",
    "        img_array = img_to_array(img) / 255.0  # Нормализация\n",
    "        images.append(img_array)\n",
    "    return np.array(images)\n",
    "\n",
    "# Загрузка изображений\n",
    "X_train = load_images(train_files)\n",
    "X_val = load_images(val_files)\n",
    "X_test = load_images(test_files)\n",
    "\n",
    "# Загрузка предварительно обученной модели EfficientNet-B0\n",
    "base_model = EfficientNetB0(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False\n",
    "x = base_model.output\n",
    "#x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation=\"relu\")(x)\n",
    "x = Dropout(0.3)(x)\n",
    "output = Dense(1, activation=\"linear\")(x)  # Линейный выход для регрессии\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=learning_rate), loss=\"mean_squared_error\", metrics=[\"mae\",\"accuracy\"])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "\n",
    "# Обучение модели\n",
    "history = model.fit(\n",
    "    X_train, train_ages,\n",
    "    validation_data=(X_val, val_ages),\n",
    "    epochs=num_epochs,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Оценка модели на тестовом наборе\n",
    "test_loss, test_mae, test_accuracy = model.evaluate(X_test, test_ages, batch_size=batch_size)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test MAE: {test_mae:.4f}, Test Accuracy: {test_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
