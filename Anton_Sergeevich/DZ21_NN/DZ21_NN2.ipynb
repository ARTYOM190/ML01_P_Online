{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbfa6b97",
   "metadata": {},
   "source": [
    "ДЗ - обучить при помощи tf (keras) API любое ДЗ по обучениею классических моделей. \n",
    "Можно сдавать на торче.\n",
    "Дедлайн 09.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7628498-e92d-4601-8114-1d282046f957",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import utils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from scipy.misc import toimage\n",
    "%matplotlib inline \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2408b2f0-6d64-4983-b699-47b66b8ff2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow[and-cuda] in d:\\soft\\programfiles\\anaconda\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in d:\\soft\\programfiles\\anaconda\\lib\\site-packages (from tensorflow[and-cuda]) (2.18.0)\n",
      "Collecting nvidia-cublas-cu12==12.5.3.2 (from tensorflow[and-cuda])\n",
      "  Downloading nvidia_cublas_cu12-12.5.3.2-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.5.82 (from tensorflow[and-cuda])\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.5.82-py3-none-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cuda-nvcc-cu12==12.5.82 (from tensorflow[and-cuda])\n",
      "  Downloading nvidia_cuda_nvcc_cu12-12.5.82-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.5.82 (from tensorflow[and-cuda])\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.5.82-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.5.82 (from tensorflow[and-cuda])\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.5.82-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.3.0.75 (from tensorflow[and-cuda])\n",
      "  Downloading nvidia_cudnn_cu12-9.3.0.75-py3-none-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.3.61 (from tensorflow[and-cuda])\n",
      "  Downloading nvidia_cufft_cu12-11.2.3.61-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.6.82 (from tensorflow[and-cuda])\n",
      "  Downloading nvidia_curand_cu12-10.3.6.82-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.3.83 (from tensorflow[and-cuda])\n",
      "  Downloading nvidia_cusolver_cu12-11.6.3.83-py3-none-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.1.3 (from tensorflow[and-cuda])\n",
      "  Downloading nvidia_cusparse_cu12-12.5.1.3-py3-none-win_amd64.whl.metadata (1.6 kB)\n",
      "INFO: pip is looking at multiple versions of tensorflow[and-cuda] to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tensorflow[and-cuda]\n",
      "  Downloading tensorflow-2.17.1-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tensorflow-intel==2.17.1 (from tensorflow[and-cuda])\n",
      "  Downloading tensorflow_intel-2.17.1-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting nvidia-cublas-cu12==12.3.4.1 (from tensorflow[and-cuda])\n",
      "  Downloading nvidia_cublas_cu12-12.3.4.1-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.3.101 (from tensorflow[and-cuda])\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.3.101-py3-none-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cuda-nvcc-cu12==12.3.107 (from tensorflow[and-cuda])\n",
      "  Downloading nvidia_cuda_nvcc_cu12-12.3.107-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.3.107 (from tensorflow[and-cuda])\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.3.107-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.3.101 (from tensorflow[and-cuda])\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.3.101-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.7.29 (from tensorflow[and-cuda])\n",
      "  Downloading nvidia_cudnn_cu12-8.9.7.29-py3-none-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.12.1 (from tensorflow[and-cuda])\n",
      "  Downloading nvidia_cufft_cu12-11.0.12.1-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.4.107 (from tensorflow[and-cuda])\n",
      "  Downloading nvidia_curand_cu12-10.3.4.107-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.5.4.101 (from tensorflow[and-cuda])\n",
      "  Downloading nvidia_cusolver_cu12-11.5.4.101-py3-none-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.2.0.103 (from tensorflow[and-cuda])\n",
      "  Downloading nvidia_cusparse_cu12-12.2.0.103-py3-none-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting tensorflow[and-cuda]\n",
      "  Downloading tensorflow-2.17.0-cp312-cp312-win_amd64.whl.metadata (3.2 kB)\n",
      "Collecting tensorflow-intel==2.17.0 (from tensorflow[and-cuda])\n",
      "  Downloading tensorflow_intel-2.17.0-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting tensorflow[and-cuda]\n",
      "  Downloading tensorflow-2.16.2-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tensorflow-intel==2.16.2 (from tensorflow[and-cuda])\n",
      "  Downloading tensorflow_intel-2.16.2-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting tensorflow[and-cuda]\n",
      "  Downloading tensorflow-2.16.1-cp312-cp312-win_amd64.whl.metadata (3.5 kB)\n",
      "Collecting tensorflow-intel==2.16.1 (from tensorflow[and-cuda])\n",
      "  Downloading tensorflow_intel-2.16.1-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "\n",
      "The conflict is caused by:\n",
      "    tensorflow[and-cuda] 2.18.0 depends on nvidia-nccl-cu12==2.21.5; extra == \"and-cuda\"\n",
      "    tensorflow[and-cuda] 2.17.1 depends on nvidia-nccl-cu12==2.19.3; extra == \"and-cuda\"\n",
      "    tensorflow[and-cuda] 2.17.0 depends on nvidia-nccl-cu12==2.19.3; extra == \"and-cuda\"\n",
      "    tensorflow[and-cuda] 2.16.2 depends on nvidia-nccl-cu12==2.19.3; extra == \"and-cuda\"\n",
      "    tensorflow[and-cuda] 2.16.1 depends on nvidia-nccl-cu12==2.19.3; extra == \"and-cuda\"\n",
      "\n",
      "To fix this you could try to:\n",
      "1. loosen the range of package versions you've specified\n",
      "2. remove package versions to allow pip to attempt to solve the dependency conflict\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Cannot install tensorflow[and-cuda]==2.16.1, tensorflow[and-cuda]==2.16.2, tensorflow[and-cuda]==2.17.0, tensorflow[and-cuda]==2.17.1 and tensorflow[and-cuda]==2.18.0 because these package versions have conflicting dependencies.\n",
      "ERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow[and-cuda]\n",
    "#!pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f8b9f6",
   "metadata": {},
   "source": [
    "Загрузим датасет титаника.\n",
    "Удалим данные с пропусками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f53196-6191-4cf3-99be-c103ea448f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "записей до удаления пропусков 891\n",
      "записей до удаления пропусков 712\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(edgeitems=30, linewidth=110000, \n",
    "    formatter=dict(float=lambda x: \"%.3g\" % x))        \n",
    "# Создаем усеченный датафрейм для дальнейшей обработки. Уберем данные о номере билета, номере каюты (мало данных), :\n",
    "df_train = pd.read_csv(\"titanic_train.csv\",encoding='Windows-1251' ,on_bad_lines='skip',\n",
    "                    #index_col='client_id' ,\n",
    "                    usecols=[1,2,4,5, 6,7,9,11]\n",
    "                    )\n",
    "print(\"записей до удаления пропусков\",len(df_train))\n",
    "df_train = df_train.dropna()\n",
    "print(\"записей до удаления пропусков\",len(df_train))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3e206b",
   "metadata": {},
   "source": [
    "Преобразуем категориальные переменные в цифры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4be3efe5-9ab5-4213-be44-4e05479dc0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked\n",
      "0           0       3    1  22.0      1      0   7.2500         2\n",
      "1           1       1    0  38.0      1      0  71.2833         0\n",
      "2           1       3    0  26.0      0      0   7.9250         2\n",
      "3           1       1    0  35.0      1      0  53.1000         2\n",
      "4           0       3    1  35.0      0      0   8.0500         2\n",
      "..        ...     ...  ...   ...    ...    ...      ...       ...\n",
      "885         0       3    0  39.0      0      5  29.1250         1\n",
      "886         0       2    1  27.0      0      0  13.0000         2\n",
      "887         1       1    0  19.0      0      0  30.0000         2\n",
      "889         1       1    1  26.0      0      0  30.0000         0\n",
      "890         0       3    1  32.0      0      0   7.7500         1\n",
      "\n",
      "[712 rows x 8 columns]\n",
      "848\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "for col in ['Sex', 'Embarked']:\n",
    "    df_train[col] = LabelEncoder().fit_transform(df_train[col])\n",
    "print(df_train)\n",
    "\n",
    "minority_class = df_train[df_train.Survived == 1]\n",
    "majority_class = df_train[df_train.Survived == 0]\n",
    "#print(len(minority_class))\n",
    "#print(len(majority_class))\n",
    "minority_upsampled = resample(minority_class, \n",
    "                              replace=True,  # Sample with replacement\n",
    "                              n_samples=len(majority_class),  # Equalize class sizes\n",
    "                              random_state=42)\n",
    "# Combine the majority class with the upsampled minority class\n",
    "df_train = pd.concat([majority_class, minority_upsampled])\n",
    "print(len(df_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5e0bd428-bcb6-4894-9744-5f40a854c513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_train['Survived']\n",
    "X = df_train[[ 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare','Embarked']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=72)\n",
    "tf.__version__\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8b0ab1de-8944-4d28-aa54-befb04c26f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Soft\\ProgramFiles\\Anaconda\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5431 - auc: 0.5987 - loss: 1.2543   \n",
      "Epoch 2/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5527 - auc: 0.6941 - loss: 0.6654 \n",
      "Epoch 3/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6738 - auc: 0.6926 - loss: 0.6568 \n",
      "Epoch 4/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6494 - auc: 0.7180 - loss: 0.6420 \n",
      "Epoch 5/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7044 - auc: 0.7485 - loss: 0.6074 \n",
      "Epoch 6/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6902 - auc: 0.7975 - loss: 0.5771 \n",
      "Epoch 7/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7049 - auc: 0.7917 - loss: 0.5812 \n",
      "Epoch 8/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7434 - auc: 0.8092 - loss: 0.5431 \n",
      "Epoch 9/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7926 - auc: 0.8415 - loss: 0.5045 \n",
      "Epoch 10/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7693 - auc: 0.8420 - loss: 0.5160 \n",
      "Epoch 11/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7937 - auc: 0.8469 - loss: 0.4935 \n",
      "Epoch 12/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7695 - auc: 0.8283 - loss: 0.5176 \n",
      "Epoch 13/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7890 - auc: 0.8529 - loss: 0.4716 \n",
      "Epoch 14/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7154 - auc: 0.7867 - loss: 0.6047 \n",
      "Epoch 15/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7681 - auc: 0.8113 - loss: 0.5388 \n",
      "Epoch 16/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7860 - auc: 0.8338 - loss: 0.4991 \n",
      "Epoch 17/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7888 - auc: 0.8601 - loss: 0.4671 \n",
      "Epoch 18/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7844 - auc: 0.8339 - loss: 0.5080 \n",
      "Epoch 19/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7827 - auc: 0.8538 - loss: 0.4784 \n",
      "Epoch 20/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8059 - auc: 0.8369 - loss: 0.4965 \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7543 - auc: 0.8119 - loss: 0.5667  \n",
      "\n",
      "Test loss : 0.52814120054245\n",
      "Test   accuracy: 0.7823529243469238\n",
      "Test   auc: 0.8408734798431396\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method TensorFlowTrainer.evaluate of <Sequential name=sequential_34, built=True>>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(model.summary())\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=0.03)\n",
    "model = Sequential()\n",
    "model.add(Dense(7, input_dim=X.shape[1], activation=\"relu\"))\n",
    "model.add(Dense(3, activation=\"relu\"))\n",
    "#model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=adam, metrics=[\"accuracy\",\"AUC\"])\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy','auc'])\n",
    "history = model.fit(X_train, y_train, batch_size=45, epochs=20, verbose = 1)\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"\\nTest loss :\", score[0])\n",
    "print('Test   accuracy:', score[1])\n",
    "print('Test   auc:', score[2])\n",
    "model.evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9488a9-2c2c-4170-9fd9-1d40ca0a51c5",
   "metadata": {},
   "source": [
    "Выводы. \n",
    "Модель обучается, если данные не имеют пропусков.\n",
    "Если в слое достаточно нейронов, дальнейшее добавление не приносит улучшения метрик.\n",
    "Минимальное количество слоев - 2. Но можно и 3, результат почти тот же.\n",
    "От запуска к запуску обучения метрики на выходе разные.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
