{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ДЗ должна быть выполнена строго на torch\n",
    "1 - использовать dataloader. \n",
    "2 - в цикл обучения добавить сохранения лучшей модели / шедулер для скорости обучения. \n",
    "3 - вывести графики обучения. Выводить информацию по обучению в процессе. \n",
    "\n",
    "Решить задачу предсказания возраста. Свести к задаче классификации. \n",
    "0- 9 10 -19 - 20 -29 30 -39 40 49 50 59 ...\n",
    " \n",
    "В качестве фьючеэкстрактора используйте любую вариацию vit. ** - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from timm.models.vision_transformer import VisionTransformer\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Конфигурация\n",
    "config = {\n",
    "    'data_root': 'C:/ML/ML01_P_Online/Eugene_Piuta/DZ_24/wiki_crop/cropped_imgs/',  \n",
    "    'csv_path': './imgs_df.csv',    \n",
    "    'batch_size': 32,\n",
    "    'num_workers': 4,\n",
    "    'lr': 0.001,\n",
    "    'epochs': 20,\n",
    "    'img_size': 128,\n",
    "    'patch_size': 16,\n",
    "    'embed_dim': 192,\n",
    "    'depth': 6,\n",
    "    'num_heads': 6,\n",
    "    'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    'save_path': 'best_model.pth'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кастомный Dataset для работы с датафреймом\n",
    "class FaceDataFrameDataset(Dataset):\n",
    "    def __init__(self, df, root_dir, transform=None):\n",
    "        self.df = df\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.classes = sorted(df['class'].unique())\n",
    "        self.num_classes = len(self.classes)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.df.iloc[idx, 0])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        label = self.df.iloc[idx, 2]  # Берем класс из третьего столбца\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Аугментации и преобразования\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((config['img_size'], config['img_size'])),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>raw</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00_102100_1970-10-09_20080.jpg</td>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00_1024100_1982-06-07_20110.jpg</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00_11328300_1980-06-10_20080.jpg</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00_1199800_1976-04-13_20120.jpg</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00_12318000_1988-06-12_20080.jpg</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6201</th>\n",
       "      <td>99_6986299_1986-05-08_20121.jpg</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6202</th>\n",
       "      <td>99_7319399_1981-08-23_20100.jpg</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6203</th>\n",
       "      <td>99_8419699_1973-07-02_20140.jpg</td>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6204</th>\n",
       "      <td>99_8551399_1972-02-25_20080.jpg</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6205</th>\n",
       "      <td>99_9863599_1948-08-13_19630.jpg</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6206 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              filename  raw  class\n",
       "0       00_102100_1970-10-09_20080.jpg   38      4\n",
       "1      00_1024100_1982-06-07_20110.jpg   29      3\n",
       "2     00_11328300_1980-06-10_20080.jpg   28      3\n",
       "3      00_1199800_1976-04-13_20120.jpg   36      4\n",
       "4     00_12318000_1988-06-12_20080.jpg   20      2\n",
       "...                                ...  ...    ...\n",
       "6201   99_6986299_1986-05-08_20121.jpg   26      3\n",
       "6202   99_7319399_1981-08-23_20100.jpg   29      3\n",
       "6203   99_8419699_1973-07-02_20140.jpg   41      5\n",
       "6204   99_8551399_1972-02-25_20080.jpg   36      4\n",
       "6205   99_9863599_1948-08-13_19630.jpg   15      1\n",
       "\n",
       "[6206 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузка датафрейма\n",
    "df = pd.read_csv(config['csv_path'])\n",
    "config['num_classes'] = len(df['class'].unique())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание датасета\n",
    "dataset = FaceDataFrameDataset(df, config['data_root'], transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение на train/val\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], \n",
    "                         shuffle=True, num_workers=config['num_workers'])\n",
    "val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], \n",
    "                        shuffle=False, num_workers=config['num_workers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модель Vision Transformer\n",
    "class FaceViT(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(FaceViT, self).__init__()\n",
    "        self.vit = VisionTransformer(\n",
    "            img_size=config['img_size'],\n",
    "            patch_size=config['patch_size'],\n",
    "            in_chans=3,\n",
    "            num_classes=config['num_classes'],\n",
    "            embed_dim=config['embed_dim'],\n",
    "            depth=config['depth'],\n",
    "            num_heads=config['num_heads'],\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.vit(x)\n",
    "\n",
    "model = FaceViT(config).to(config['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Замораживаем все параметры ViT\n",
    "for param in model.vit.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Размораживаем только голову классификации\n",
    "for param in model.vit.head.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Критерий и оптимизатор\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=config['lr'])\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция валидации\n",
    "def validate(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(config['device'])\n",
    "            labels = labels.to(config['device'])\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    val_loss = running_loss / len(val_loader)\n",
    "    val_acc = 100 * correct / total\n",
    "    \n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для отрисовки графиков\n",
    "def plot_metrics(train_loss, val_loss, train_acc, val_acc):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_loss, label='Train Loss')\n",
    "    plt.plot(val_loss, label='Val Loss')\n",
    "    plt.title('Loss History')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_acc, label='Train Accuracy')\n",
    "    plt.plot(val_acc, label='Val Accuracy')\n",
    "    plt.title('Accuracy History')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_metrics.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение модели\n",
    "def train_model():\n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "    train_acc_history = []\n",
    "    val_acc_history = []\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(config['epochs']):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        # Progress bar\n",
    "        pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{config[\"epochs\"]}', unit='batch')\n",
    "        \n",
    "        for images, labels in pbar:\n",
    "            images = images.to(config['device'])\n",
    "            labels = labels.to(config['device'])\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            pbar.set_postfix({\n",
    "                'loss': running_loss / (pbar.n + 1),\n",
    "                'acc': 100 * correct / total\n",
    "            })\n",
    "        \n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc = 100 * correct / total\n",
    "        train_loss_history.append(train_loss)\n",
    "        train_acc_history.append(train_acc)\n",
    "        \n",
    "        # Валидация\n",
    "        val_loss, val_acc = validate(model, val_loader, criterion)\n",
    "        val_loss_history.append(val_loss)\n",
    "        val_acc_history.append(val_acc)\n",
    "        \n",
    "        # Шедулер\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Сохранение лучшей модели\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), config['save_path'])\n",
    "            print(f'Model saved with val_loss: {val_loss:.4f}')\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{config[\"epochs\"]}')\n",
    "        print(f'Train Loss: {train_loss:.4f}, Acc: {train_acc:.2f}%')\n",
    "        print(f'Val Loss: {val_loss:.4f}, Acc: {val_acc:.2f}%')\n",
    "        print('-' * 50)\n",
    "    \n",
    "    # Графики\n",
    "    plot_metrics(train_loss_history, val_loss_history, train_acc_history, val_acc_history)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda\n",
      "Number of classes: 10\n",
      "Train samples: 4964, Val samples: 1242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:   0%|          | 0/156 [00:00<?, ?batch/s]"
     ]
    }
   ],
   "source": [
    "# Запуск обучения\n",
    "if __name__ == '__main__':\n",
    "    print(f\"Training on {config['device']}\")\n",
    "    print(f\"Number of classes: {config['num_classes']}\")\n",
    "    print(f\"Train samples: {len(train_dataset)}, Val samples: {len(val_dataset)}\")\n",
    "    \n",
    "    model = train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Максимально было достигнуто accuracy 42%. Потом все поломалось и перестало работать)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
