{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируются необходимые библиотеки: pandas и numpy для работы с данными, sklearn для масштабирования данных, scipy для статистических расчетов, seaborn и matplotlib для визуализации данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка данных из CSV файла credit_train.csv с указанием разделителя ;, десятичного разделителя , и кодировки windows-1251"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных\n",
    "df = pd.read_csv('credit_train.csv', sep=';', decimal=',', encoding='windows-1251')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаление всех строк с пропущенными значениями из DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Обработка пропусков (удаление строк с пропусками)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбор только числовых столбцов из DataFrame для дальнейшей обработки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Фильтрация числовых столбцов\n",
    "numeric_df = df.select_dtypes(include=[np.number])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Расчет Z-оценок для всех числовых столбцов и удаление строк с выбросами, где абсолютное значение Z-оценок больше 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Оценка выбросов\n",
    "z_scores = np.abs(stats.zscore(numeric_df))\n",
    "numeric_df_no_outliers = numeric_df[(z_scores < 3).all(axis=1)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычисление корреляционной матрицы для числовых столбцов без выбросов и визуализация матрицы корреляций с помощью тепловой карты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Корреляция\n",
    "correlation_matrix = numeric_df_no_outliers.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title(\"Корреляционная матрица\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведение теста Шапиро-Уилка на нормальность распределения для каждого числового столбца без выбросов. Вывод результатов теста для каждой колонки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Тест на нормальность распределения\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "for column in numeric_df_no_outliers.columns:\n",
    "    stat, p = shapiro(numeric_df_no_outliers[column])\n",
    "    print(f'{column}: p-value={p}')\n",
    "    if p > 0.05:\n",
    "        print(f'Колонка {column} имеет нормальное распределение\\n')\n",
    "    else:\n",
    "        print(f'Колонка {column} не имеет нормального распределения\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Масштабирование данных с использованием MinMaxScaler, приведение значений каждого столбца к диапазону от 0 до 1. Создание нового DataFrame с масштабированными данными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Масштабирование данных\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(numeric_df_no_outliers)\n",
    "df_scaled = pd.DataFrame(scaled_data, columns=numeric_df_no_outliers.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохранение преобразованных данных в новый CSV файл credit_train_processed.csv без индексации строк."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение преобразованных данных\n",
    "df_scaled.to_csv('credit_train_processed.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот код помогает подготовить данные для дальнейшего анализа или использования в моделях машинного обучения. Сначала загружаются данные из файла credit_train.csv и удаляются строки с пропущенными значениями. Затем из данных выбираются только числовые столбцы. Оцениваются и удаляются экстремальные значения (выбросы). Считается корреляция между числовыми данными, и строится тепловая карта для визуализации этих корреляций. После этого проводится тест на нормальность распределения для каждого числового столбца. Затем данные масштабируются так, чтобы все значения были в диапазоне от 0 до 1. Наконец, обработанные данные сохраняются в новый файл credit_train_processed.csv. В результате мы также получаем рисунок, отображающий корреляционную матрицу."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
