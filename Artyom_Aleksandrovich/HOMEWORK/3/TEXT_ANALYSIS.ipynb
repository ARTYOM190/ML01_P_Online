{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Анализ текста\n",
    "\n",
    "Импортируем все необходимое\n",
    "import re: Импортирует модуль для работы с регулярными выражениями, который позволяет выполнять сложные текстовые манипуляции.\n",
    "from collections import Counter: Импортирует класс Counter из модуля collections, который используется для подсчета объектов (например, слов) в списке.\n",
    "import spacy: Импортирует библиотеку Spacy, которая предназначена для обработки естественного языка.\n",
    "from Levenshtein import ratio: Импортирует функцию ratio из библиотеки Levenshtein для вычисления расстояния Левенштейна, которое измеряет схожесть между двумя строками.\n",
    "from spacy.lang.en.stop_words import STOP_WORDS: Импортирует предопределенный список стоп-слов из Spacy, которые часто не несут значимого смысла в тексте (например, \"и\", \"но\", \"или\").\n",
    "from string import punctuation: Импортирует строку, содержащую все знаки препинания (например, \".\", \",\", \"!\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "import spacy\n",
    "from Levenshtein import ratio\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция read_file принимает путь к файлу (file_path) и открывает файл в режиме чтения с кодировкой UTF-8.\n",
    "Читает содержимое файла и возвращает его как строку.\n",
    "Функция для чтения файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция clean_text очищает текст, приводя его к нижнему регистру.\n",
    "Удаляет все знаки препинания с помощью регулярного выражения.\n",
    "Разбивает текст на отдельные слова.\n",
    "Исключает стоп-слова из списка слов.\n",
    "Возвращает очищенный текст в виде строки.\n",
    "Функция для очистки текста от стоп-слов и знаков препинания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()  #Приведение текста к нижнему регистру\n",
    "    text = re.sub(f'[{re.escape(punctuation)}]', '', text)  #Удаление знаков препинания\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in STOP_WORDS]  #Исключение стоп-слов\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция count_unique_words разбивает текст на слова.\n",
    "Преобразует список слов в множество, чтобы удалить дубликаты.\n",
    "Возвращает количество уникальных слов.\n",
    "Функция для подсчета уникальных слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_unique_words(text):\n",
    "    words = text.split()\n",
    "    unique_words = set(words)\n",
    "    return len(unique_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция count_vowels_consonants определяет списки гласных и согласных букв.\n",
    "Использует генераторы списка для подсчета гласных и согласных в тексте.\n",
    "Возвращает количество гласных и согласных букв.\n",
    "Функция для подсчета гласных и согласных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_vowels_consonants(text):\n",
    "    vowels = \"aeiou\"\n",
    "    consonants = \"bcdfghjklmnpqrstvwxyz\"\n",
    "    \n",
    "    vowels_count = sum(1 for char in text if char in vowels)\n",
    "    consonants_count = sum(1 for char in text if char in consonants)\n",
    "    \n",
    "    return vowels_count, consonants_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция analyze_sentences_words загружает небольшую модель Spacy.\n",
    "Применяет модель к тексту, чтобы разметить предложения и слова.\n",
    "Извлекает предложения и подсчитывает их количество.\n",
    "Вычисляет длину каждого предложения.\n",
    "Извлекает слова и подсчитывает их частоту.\n",
    "Функция для подсчета предложений, их длины и частоты слов с критерием схожести"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentences_words(text):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    sentences = list(doc.sents)\n",
    "    num_sentences = len(sentences)\n",
    "    \n",
    "    sentence_lengths = [len(sent.text.split()) for sent in sentences]\n",
    "    \n",
    "    words = [token.text.lower() for token in doc if token.is_alpha]\n",
    "    word_freq = Counter(words)\n",
    "    \n",
    "    return num_sentences, sentence_lengths, word_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция process_words_with_similarity итерирует по списку слов и проверяет их схожесть с уникальными словами, используя расстояние Левенштейна.\n",
    "Если слово достаточно похоже на уже встреченное слово, увеличивает его счетчик частоты.\n",
    "Если слово уникально, добавляет его в список уникальных слов и увеличивает его счетчик.\n",
    "Функция для обработки слов с использованием расстояния Левенштейна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_words_with_similarity(words, threshold=0.8):\n",
    "    unique_words = []\n",
    "    word_freq = Counter()\n",
    "    \n",
    "    for word in words:\n",
    "        is_unique = True\n",
    "        for uw in unique_words:\n",
    "            if ratio(word, uw) > threshold:\n",
    "                word_freq[uw] += 1\n",
    "                is_unique = False\n",
    "                break\n",
    "        if is_unique:\n",
    "            unique_words.append(word)\n",
    "            word_freq[word] += 1\n",
    "    \n",
    "    return word_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для вывода топ-10 часто встречаемых слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_words(word_freq, top_n=10):\n",
    "    return word_freq.most_common(top_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основная программа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'C:\\Users\\1neon\\Desktop\\fightclub.txt'  # Указанный путь к файлу\n",
    "text = read_file(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очистка текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text = clean_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подсчет уникальных слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words_count = count_unique_words(cleaned_text)\n",
    "print(f\"Число уникальных слов: {unique_words_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подсчет гласных и согласных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vowels_count, consonants_count = count_vowels_consonants(cleaned_text)\n",
    "print(f\"Число гласных: {vowels_count}\")\n",
    "print(f\"Число согласных: {consonants_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Анализ предложений и слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sentences, sentence_lengths, word_freq = analyze_sentences_words(cleaned_text)\n",
    "print(f\"Число предложений: {num_sentences}\")\n",
    "print(f\"Длины предложений: {sentence_lengths}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обработка слов с критерием схожести"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = cleaned_text.split()\n",
    "similarity_word_freq = process_words_with_similarity(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Топ-10 часто встречаемых слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = get_top_words(similarity_word_freq)\n",
    "print(\"\\nТоп-10 часто встречаемых слов:\")\n",
    "for word, freq in top_words:\n",
    "    print(f\"'{word}': {freq} раз\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод: \n",
    "Число уникальных слов: 5127\n",
    "Число гласных: 44254\n",
    "Число согласных: 82120\n",
    "Число предложений: 218\n",
    "Длины предложений: [519, 83, 82, 50, 373, 237, 111, 65, 9, 1, 2, 7, 2, 2, 1, 7, 74, 7, 7, 86, 77, 99, 196, 39, 514, 44, 212, 113, 150, 1, 46, 186, 86, 11, 16, 162, 229, 134, 4, 147, 146, 89, 88, 5, 297, 200, 231, 361, 55, 28, 282, 405, 5, 27, 5, 111, 275, 33, 211, 1, 1, 1, 1, 309, 94, 244, 2, 1, 1, 324, 21, 8, 2, 2, 2, 116, 139, 137, 148, 151, 95, 222, 112, 477, 65, 34, 23, 29, 115, 80, 276, 174, 174, 41, 9, 50, 4, 24, 121, 56, 727, 3, 108, 359, 11, 145, 238, 949, 94, 163, 154, 27, 221, 21, 90, 2, 7, 37, 226, 59, 98, 1, 1, 1, 1, 1, 1, 231, 9, 298, 19, 95, 11, 57, 174, 654, 30, 36, 150, 272, 333, 29, 161, 17, 110, 95, 97, 1, 1, 1, 6, 2, 43, 26, 1, 10, 65, 201, 44, 147, 167, 329, 111, 140, 100, 26, 1, 1, 34, 107, 4, 15, 2, 431, 44, 401, 22, 213, 120, 33, 15, 1, 22, 177, 24, 240, 236, 14, 1, 1, 1, 9, 1, 3, 48, 20, 31, 136, 71, 49, 243, 1, 1, 1, 173, 15, 66, 91, 19, 46, 587, 59, 93, 15, 1, 27, 2, 42]\n",
    "\n",
    "Топ-10 часто встречаемых слов:\n",
    "'tyler': 677 раз\n",
    "'marla': 342 раз\n",
    "'says': 326 раз\n",
    "'fight': 246 раз\n",
    "'club': 185 раз\n",
    "'dont': 147 раз\n",
    "'said': 138 раз\n",
    "'im': 135 раз\n",
    "'guy': 134 раз\n",
    "'know': 130 раз\n",
    "PS C:\\Users\\1neon>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
